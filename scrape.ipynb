{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/adri/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/adri/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing keys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "GEM_KEY = os.environ.get(\"GEM_KEY\")\n",
    "DEEP_KEY = os.environ.get(\"DEEP_APIKEY\")\n",
    "HF_API_TOKEN = os.environ.get(\"HF_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping job list page: https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Data%20Scientist&location=London&f_WT=2&start=0\n",
      "{'title': 'Data Scientist', 'company': 'Prolific', 'location': 'London, England, United Kingdom', 'url': 'https://uk.linkedin.com/jobs/view/data-scientist-at-prolific-4179910842?position=1&pageNum=0&refId=xHXMNW9Pvvzf%2FgSYQUOBIA%3D%3D&trackingId=CUYRKFx9XKvn4FjBiAZ7TA%3D%3D', 'description': \"Data TeamProlificProlific another player AI space â€“ architects human data infrastructure 's reshaping landscape AI development . world foundational AI technologies increasingly commoditized , 's quality diversity human-generated data truly differentiates products models.The roleWe 're looking Data Scientist strong analytical skills passion solving complex problems join team . 'll work cross-functionally product engineering teams , driving initiatives unlock power vast datasets . 'll significant autonomy design , build , deploy models , develop measurement frameworks , help influence decisions directly impact platform 's capabilities business strategy . data function supports multiple areas business , giving exposure diverse challenges allowing develop deep expertise specific domains based interests business priorities.What 'll bring roleExperience interest working human behavioral data , annotation/labeling systems , projects involving human feedback AI development evaluationExperience building measurement systems analytical frameworks , experimental design , causal inference methods , multi-dimensional evaluation metricsProficiency working modern foundation models understanding leverage versus traditional ML approachesSolid software engineering fundamentals expertise Python/R , SQL , AI/ML frameworks , modern data science stackA toolkit spanning classical statistical methods state-of-the-art ML techniques , knowledge choose apply right tool unique problemProven ability effectively communicate influence stakeholders across organization , engineers executivesAbility thrive fast-paced environments balance speed qualityStrong prioritization skills , consistently focusing high-impact workWhat 'll roleDevelop implement sophisticated models algorithms assess improve quality integrity human data platformCollaborate closely product managers engineers identify opportunities data science drive product innovation user valueSynthesize complex analyses actionable insights , presenting compelling data-driven narratives influence strategic decisionsEvaluate implement cutting-edge data science methodologies tools , ensuring team stays forefront fieldPartner data engineers enhance data pipelines , logging systems , MLOps practices , creating robust foundation advanced analytics modelingWhy Prolific great place workWe 've built unique platform connects researchers companies global pool participants , enabling collection high-quality , ethically sourced human behavioral data feedback . data cornerstone developing accurate , nuanced , aligned AI systems.We believe next leap AI capabilities wo n't come solely scaling existing models , integrating diverse human perspectives behaviors AI development . providing crucial human data infrastructure , Prolific positioning forefront next wave AI innovation â€“ one reflects breath best humanity.Working us place forefront AI innovation , providing access unique human data platform opportunities groundbreaking research . Join us enjoy competitive salary , benefits , remote working within impactful , mission-driven culture.Links information ProlificBenefitsExternal HandbookWebsiteYoutubePrivacy StatementBy submitting application , agree Prolific may collect personal data recruiting global organisation planning . Prolific 's Candidate Privacy Notice explains personal information Prolific may process , Prolific may process personal information , purposes processing personal information , rights exercise Prolific use personal information .\"}\n",
      "{'title': 'Senior Data Scientist', 'company': 'Cint', 'location': 'London, England, United Kingdom', 'url': 'https://uk.linkedin.com/jobs/view/senior-data-scientist-at-cint-4182578905?position=2&pageNum=0&refId=xHXMNW9Pvvzf%2FgSYQUOBIA%3D%3D&trackingId=vHUQS%2BHy8lMPJ2PRZXMKzQ%3D%3D', 'description': \"Company DescriptionWho AreCint pioneer research technology ( ResTech ) . customers use Cint platform post questions get answers real people build business strategies , confidently publish research , accurately measure impact digital advertising , . Cint platform built programmatic marketplace , world â€™ largest , nearly 300 million respondents 150 countries consent sharing opinions , motivations , behaviours.We feeding world â€™ curiosity ! Job DescriptionAs Senior Data Scientist Cint opportunity collaborate closely product engineering teams work key Identity Trust & Safety products initiatives . role involves data mining analytics , product data validation , development statistical machine learning-based methodologies . ideal candidate strong ability independently research , develop , maintain products align Cint â€™ capabilities market needs.ResponsibilitiesLead research , discovery , development phases new existing products , primarily focusing Identity Trust & Safety.Independently confidently carry project planning , development , maintenance end end minimal supervision.Analyze large , diverse datasets extract impactful insights guide product strategy.Collaborate cross-functional teams design , implement , test new existing products developing maintaining statistical machine learning methods . Lead full-cycle development machine learning solutions , including model development , deployment , maintenance , performance evaluation , ensuring seamless integration production environments.Continuously evaluate validate internal external products ensure Cint 's continued success.Communicate insights recommendations effectively visualizations presentations resonate diverse audiences.QualificationsRequired : Must minimum 3-5 years working experience Data Science capacity.A Master 's degree ( equivalent ) Statistics , Quantitative Sciences , Data Science , Operations Research , quantitative fields.Ability manipulate , analyze , interpret large datasets independently.Deep understanding advanced statistical techniques concepts ( e.g. , properties distributions , hypothesis testing , parametric/non-parametric tests , survey design , sampling theory , experimental design , including multivariate testing , regression/predictive modeling , causal inference , A/B testing ) .Strong knowledge various machine learning techniques ( clustering , regression , decision trees , etc . ) real-world advantages drawbacks.Working knowledge application statistical modeling techniques.Comfortable researching learning new methods , tools , techniques.Ability independently confidently manage projects start finish minimal supervision.Proficiency Python ( statistical ML package tools ) .Proficiency SQL working large-scale databases.Additional InformationNice : Experience Fraud Detection Prevention methodologies.Experience working Identity vendors.Knowledge Identity graph methodologies.Experience Databricks using scalable data processing machine learning workflows.Experience working big data technologies ( e.g . Spark , PySpark ) .Our ValuesCollaboration superpowerWe uncover rich perspectives across worldSuccess happens togetherWe deliver across borders.Innovation bloodWe â€™ pioneers industryOur curiosity insatiableWe bring best ideas life.We SayWe â€™ accountable work actionsExcellence comes standardWe â€™ open , honest kind , always.We caringWe learn â€™ experiencesStop listen ; every opinion mattersWe embrace diversity , equity inclusion.More CintIn June 2021 , Cint acquired Berlin-based GapFish â€“ world â€™ largest ISO certified online panel community DACH region â€“ January 2022 , completed acquisition US-based Lucid â€“ programmatic research technology platform provides access first-party survey data 110 countries.Cint Group AB ( publ ) , listed Nasdaq Stockholm , growth made Cint strong global platform teams across many global offices , including Stockholm , London , New York , New Orleans , Singapore , Tokyo Sydney . ( www.cint.com )\"}\n",
      "{'title': 'Senior Data Scientist (Commodities)', 'company': 'Fuse Energy', 'location': 'London, England, United Kingdom', 'url': 'https://uk.linkedin.com/jobs/view/senior-data-scientist-commodities-at-fuse-energy-4001460608?position=3&pageNum=0&refId=xHXMNW9Pvvzf%2FgSYQUOBIA%3D%3D&trackingId=XwuTCqqLXB88b51laxtIfA%3D%3D', 'description': 'currently seeking Senior Data Scientist strong background statistics join team . role responsible developing implementing models energy supply business . Senior Data Scientist , work closely engineering team ensure accuracy effectiveness models.Responsibilities : Develop implement models energy supply business using Python data science toolsIdentify , analyze , mitigate credit riskConduct data analysis modeling support risk management decisionsStay current industry developments regulations related credit risk managementRequirements2+ years experience data scientistStrong programming skills Python experience data science tools Pandas , NumPy , SciPyStrong statistical modeling skillsStrong communication collaboration skillsExperience energy industry plusBenefitsCompetitive salary stock options sign-on bonusBiannual bonus schemeFully expensed tech match needs ! 28 days paid annual leave per year including public holiday'}\n",
      "{'title': 'Data Science Manager', 'company': 'Ravelin Technology', 'location': 'London, England, United Kingdom', 'url': 'https://uk.linkedin.com/jobs/view/data-science-manager-at-ravelin-technology-4170776263?position=4&pageNum=0&refId=xHXMNW9Pvvzf%2FgSYQUOBIA%3D%3D&trackingId=l%2Bb6%2FSnYgasObxbuEXgaXw%3D%3D', 'description': \"? Hi ! ðŸ‘‹ Ravelin ! 're fraud detection company using advanced machine learning network analysis technology solve big problems . goal make online transactions safer help clients feel confident serving customers.And fun meantime ! friendly bunch pride strong culture adhering values empathy , ambition , unity integrity . really value work/life balance embrace flat hierarchy structure company-wide . Join us 'll learn fast cutting-edge tech work brightest nicest people around - check Glassdoor reviews.If sounds like cup tea , would love hear ! information check blog see would like help us prevent crime protect world 's biggest online businesses.The TeamYou joining Detection team . Detection team responsible keeping fraud rates low - clients happy - continuously developing , training deploying machine learning models . aim make model deployments easy error free code deployments . Google 's Best Practices ML Engineering bible.Our models trained spot multiple types fraud , using variety data sources techniques real time . prediction pipelines strict SLAs , every prediction must returned 300ms . models performing expected , 's Detection team investigate why.The Detection team core Ravelin 's success . work closely Data Engineering Team build infrastructure Intelligence & Investigations Team liaise clients.The RoleWe currently looking Data Scientist line manage data scientists ML engineers drive innovation across suite fraud detection products . 'll work closely product , engineering operations teams develop ML models ML products deliver current future clients . ideal candidate pragmatic , approachable filled knowledge tempered past failures.You hire , coach develop talented data science team deliver ML product roadmap . element working people . 'll partner closely senior members Detection discover new avenues ML product innovation . time time , 're excited even software model development yourself.The work green field research . everyday work making safe incremental progress towards better models clients . ideal candidate willing get involved aspects job - understand important.ResponsibilitiesAct leader establishing excellence across data science within detection teamLine manage team data scientists - providing coaching guidance support ongoing development growth teamResearch new techniques disrupt fraudulent behaviourInvestigate model performance issuesDevelop deploy new models detect fraud whilst maintaining SLAsLiaise product , engineering operations question assumptions ensure make right ML product decisionsRequirementsMinimum 1 year experience data science engineering manager , managing least 3 peopleYou strong collaborator colleagues outside immediate team , example client operations teams , product , engineering senior leadershipYou know manage retain talented engineers data scientists diverse range backgrounds personalities . handle difficult management situations tact , empathy supportYou significant experience building deploying ML models using Python data stackYou understand software engineering best practices ( version control , unit tests , code reviews , CI/CD ) apply machine learning engineeringNice havesExperience Go , C++ , Java another systems languageExperience Docker , Kubernetes ML production infrastructureTensorflow Pytorch deep learning experienceExperience using dbt.BenefitsFlexible Working Hours & Remote-First Environment â€” Work 're productive , flexibility supportComprehensive BUPA Health Insurance â€” Stay covered top-tier medical care peace mindÂ£1,000 Annual Wellness Learning Budget â€” Prioritise health well-being funds fitness , mental health , moreMonthly Wellbeing Learning Day â€” Take every last Friday month recharge , us25 Days Holiday + Bank Holidays + 1 Extra Cultural Day â€” Enjoy generous time rest , travel , celebrate matters youMental Health Support via Spill â€” Access professional mental health services need themAviva Pension Scheme â€” Plan future pension programRavelin Gives Back â€” Join monthly charitable donations volunteer opportunities make positive impactFortnightly Randomised Team Lunches â€” Connect teammates across company person remote lunches every weekCycle-to-Work Scheme â€” Save commuting costs staying activeBorrowMyDoggy Access â€” Love dogs ? Spend time furry friend unique perkWeekly Board Game Nights & Social Budget â€” Unwind weekly board games plan socials , supported company budget * Job offers may withdrawn candidates meet pre-employment checks : unspent criminal convictions , employment verification , right work . *\"}\n",
      "{'title': 'Associate Data Scientist', 'company': 'Spotlight Sports Group', 'location': 'London, England, United Kingdom', 'url': 'https://uk.linkedin.com/jobs/view/associate-data-scientist-at-spotlight-sports-group-4176180734?position=5&pageNum=0&refId=xHXMNW9Pvvzf%2FgSYQUOBIA%3D%3D&trackingId=U8umSF%2B1EtgukWpDVtGh5g%3D%3D', 'description': \"Spotlight Sports Group global media technology company specialising content data within sports betting , horse racing fantasy sports . 400 employees , group operates multiple award-winning brands , including Racing Post , world 's largest horse racing affiliate , Pickswise , myracing Free Super Tips . partner leading operators across betting industry produce build multilingual , best-in-class digital products content engage educate customers . ICS-digital , international marketing agency including ICS-translate , also operates group.Job PurposeWe seeking Associate Data Scientist join passionate Sports Content Generation ( CG ) lead innovation within SSG . CG team comprises Data Scientists , Content Developers Software Engineers work alongside rest Product Team ( Product Managers , UX Designers Researchers ) collaborate business stakeholders create market leading products.The successful candidate intrinsically involved development unique , rich authoritative sports content data initiatives , engineered help engage sports fans help find smart ways bet.Working collaboratively subject matter experts team , run analytical experiments evaluate alternate models via theoretical approaches enable scaling initiatives grow digital business B2B B2C products ventures.In role developing live products ability write robust , scalable code essential.Data Science established discipline Spotlight Sports Group , giving successful candidate exciting opportunity help shape future content customer experience building analytical tools generate insight , recognise patterns predict behaviour , deliver quality content directly customers . work alongside report Lead Data Scientist team help business realise opportunities arising horse racing , customer sports data.The ideal candidate adept using models test effectiveness different courses action . must strong experience using variety data mining/data analysis methods , using variety data tools , building implementing models , using/creating algorithms creating/running simulations . right candidate passion discovering solutions hidden large data sets working stakeholders improve business outcomes.Key accountabilitiesWhilst specific responsibilities dependent upon changing needs Spotlight Sports Group , following provides overview key responsibilities : Research develop custom data models algorithms apply data setsDevelop processes tools monitor analyse model performance data accuracyCollaborate product management , subject matter experts engineering departments understand company needs devise possible solutions emphasis quality , innovation scalability within agreed timeframeCommunicate results ideas key decision makersKeep date latest technology trends adapt accordinglyImplement new statistical mathematical methodologies needed specific models analysisOptimise joint development efforts appropriate database use project designWork within agreed agile methodology manage workloads effectivelyWrite scalable robust code relied upon production environment.RequirementsA Masters PHD quantitative discipline mathematics , physics , computer science statistics.Demonstrable interest experience manipulating sports data , ideally predicting outcomes sports eventsSome commercial experience manipulating data sets building statistical models - although graduates consideredStrong problem solving skills hands-on mindset emphasis product developmentExperience using statistical computer languages ( R , Python , SQL etc . ) manipulate data draw insights large data setsExperience creating using variety machine learning techniques ( clustering , decision tree learning , artificial neural networks , etc . ) knowledge real-world advantages/drawbacksKnowledge advanced statistical techniques concepts ( regression , properties distributions , statistical tests proper usage , etc . ) experience applicationsPractical experience using common data science packages pandas NumPy , along deep learning frameworks Tensorflow Pytorch.Experience using LLMs understanding application business use casesPersonal SkillsExcellent written verbal communication skills ; able clearly articulate concepts , ideas requirements understood technical non-technical teamsA drive learn master new technologies techniquesHighly self-motivated passion succeed individual part teamExcellent attention detail keen eye accuracyExcellent time management skills ability work meet deadlinesAbility gain respect & trust people work consistently demonstrating commitment workBenefitsWe offer range well-being initiatives , including private medical insurance , excellent parental leave , working globally policy , mental health support , assistance programs , social gatherings . also provide pension scheme various benefit schemes . Plus , get birthdays work enjoy 25 days holiday per year , well opportunity buy 5 additional days per year flexible use public holidays.We 've also got covered life assurance exclusive perks like Star card Step Awards ( employee recognition program ) recognise dedication . working via hybrid model ( office home ) 've made commuting easier Season Ticket Loan Cycle Work Scheme.You also take advantage complimentary access Racing Post Members Club , complete Ultimate Membership . believe making positive impact beyond workplace , 'll chance volunteer two days per year charity partner , Autism Racing .\"}\n",
      "{'title': 'Data Scientist - Work From Home', 'company': 'Outlier', 'location': 'London, England, United Kingdom', 'url': 'https://uk.linkedin.com/jobs/view/data-scientist-work-from-home-at-outlier-4181838715?position=6&pageNum=0&refId=xHXMNW9Pvvzf%2FgSYQUOBIA%3D%3D&trackingId=Zk6cXmToIZjXVJSFnVW8gQ%3D%3D', 'description': \"AboutOutlier helps world â€™ innovative companies improve AI models providing human feedback . experienced Math Expert would like lend expertise train AI models ? opportunity : Outlier looking talented Math Experts help train generative artificial intelligence modelsThis freelance opportunity remote hours flexible , work whenever best youYou may contribute expertise byâ€¦ Assessing factuality relevance domain-specific text produced AI modelsCrafting answering questions related MathEvaluating ranking domain-specific responses generated AI models Examples desirable expertise : Master 's higher degree Math related subjectExperience working Math professionalAbility write clearly concepts related Math fluent EnglishPayment : Currently , pay rates core project work Math experts UK range $ 30 $ 50 USD per hourRates vary based expertise , skills assessment , location , project need , factors . example , higher rates may offered PhDs . non-core work , initial project onboarding project overtime phases , lower rates may apply . Certain projects offer incentive payments . Please review payment terms project .\"}\n",
      "{'title': 'Applied AI Engineer', 'company': 'Fuse Energy', 'location': 'London, England, United Kingdom', 'url': 'https://uk.linkedin.com/jobs/view/applied-ai-engineer-at-fuse-energy-4169761208?position=7&pageNum=0&refId=xHXMNW9Pvvzf%2FgSYQUOBIA%3D%3D&trackingId=l7HKQZMNp51ytbW4FxgPFQ%3D%3D', 'description': 'Fuse Energy , transforming energy sector innovative solutions empower consumers . continue scale , building cutting-edge AI team play critical role developing intelligent , consumer-facing features , well internal tools drive productivity innovation across company.Role Overview : looking Applied AI Engineer join growing team Fuse Energy . position ideal engineer possesses technical expertise backend engineer specifically interested applied AI used enhance energy experience customers internal operations . Applied AI Engineer , work variety exciting projects , including consumer-focused features like Energy Co-pilot Speedy Onboarding process ( leveraging tools VLM/LLM ) . also collaborate across teams build AI tools enhance productivity streamline processes within Fuse Energy.RequirementsDesign , develop , deploy AI-powered features directly impact consumer experiences , including personalised energy recommendations seamless onboarding via AI models ( e.g. , using energy bills quick setup ) Build optimise internal AI tools make whole company productive , focus automation enhancing workflowsCollaborate backend engineers data scientists integrate AI-driven features platformsContinuously improve optimise AI models ( including LLM VLM ) provide better user experienceDevelop scalable , maintainable AI infrastructure support growing set consumer-facing internal AI featuresCollaborate trading operations teams ensure AI models aligned real-time market conditions energy pricingImprove AI models optimise trading strategies anticipating market shifts based weather demand forecastsStay date latest advancements applied AI machine learning , apply solve real-world problems within energy spaceMonitor performance AI tools models , ensuring functioning efficiently effectivelySkills & Qualifications : Minimum 4 years engineering experienceProven experience Backend Engineer strong interest practical experience applied AI machine learningStrong programming skills Python ( similar languages ) familiarity AI/ML libraries ( TensorFlow , PyTorch , etc . ) Experience working large-scale models ( LLM/VLM ) deploying AI-driven solutions productionSolid understanding cloud technologies , containerization , building scalable AI applicationsAbility integrate AI/ML models real-world applications , focusing usability performanceStrong problem-solving skills practical approach implementing AI solutions fast-paced environmentFamiliarity cloud-based platforms ( AWS plus ) services related AI/ML plusExperience strong interest energy markets trading strategiesUnderstanding weather forecasting , energy demand patterns , production modellingExperience working large datasets , particularly relation demand supply forecastingBonus : Experience energy utilities industryExposure Natural Language Processing ( NLP ) related fieldsFamiliarity data engineering practices working large datasetsBenefitsCompetitive salary stock options sign-on bonusBiannual bonus schemeFully expensed tech match needs ! Paid annual leaveBreakfast dinner office based employees'}\n",
      "{'title': 'Head of Data Science & AI', 'company': 'KDR Talent Solutions', 'location': 'London Area, United Kingdom', 'url': 'https://uk.linkedin.com/jobs/view/head-of-data-science-ai-at-kdr-talent-solutions-4184894356?position=8&pageNum=0&refId=xHXMNW9Pvvzf%2FgSYQUOBIA%3D%3D&trackingId=w3Ya0KZy4JEs5X3Q1jv6gg%3D%3D', 'description': 'Head Data Science & AI â€“ Hybrid ( Adhoc travel London ) - Â£100,000-Â£125,000 + Car Allowance + Bonus + PackageWe â€™ proud partnered client , global innovation transformation consultancy , seeking aHead Data Science & AIto help shape deliver cutting-edge AI solutions across private public sectors clients.About RoleAs Head Data Science & AI , sit intersection business strategy advanced technology , helping clients navigate complexities AI adoption . identify high-impact AI use cases , design comprehensive implementation roadmaps , oversee large-scale transformation programs align business objectives.You â€™ work across industries functions , collaborating diverse team strategists , technologists , consultants deliver meaningful results . role offers chance influence C-suite decision-makers , lead multidisciplinary teams , drive future AI innovation organisations worldwide.What â€™ DoingStrategic AI Consulting : Collaborate client stakeholders assess business challenges , identify AI opportunities , define tailored roadmaps.Use Case Prioritisation : Discover impactful AI applications , estimate ROI , prioritize initiatives based feasibility value.End-to-End Oversight : Lead implementation AI solutions business processes , ensuring alignment strategic goals.Performance Measurement : Develop frameworks track success AI projects business impact.Team Leadership : Guide mentor cross-functional teams , including data engineers , software developers , agile coaches , AI experts.Business Development : Partner leadership foster new client relationships drive opportunities groundbreaking AI projects.Thought Leadership : Stay forefront AI trends technologies , sharing insights identifying opportunities clients innovate.What â€™ Looking For8+ years experience technology strategy roles , ideally within consulting , blue-chip companies , startups.At least 2 years managerial experience top-tier strategy consulting senior consulting roles.A strong strategic mindset combined passion technology innovation.Excellent analytical communication skills , ability engage senior stakeholders.Flexibility willingness travel required.Why Join ? client values ingenuity collaboration , creating opportunities complexity . 4,000 specialists globally , diverse teams deliver transformative results across consumer manufacturing , defence security , energy utilities , financial services , healthcare , more.You receive industry-leading training , mentorship , career development opportunities , working exciting projects shaping future AI . flexible hybrid working model , prioritize professional growth work-life balance.Interested ? forward-thinking AI strategist thrives intersection business technology , â€™ love hear . â€™ worry â€™ tick every box ; encourage brilliant candidates apply.Apply KDR Recruitment take next step career .'}\n",
      "{'title': 'ML Research Engineer â€” Natural Language Processing', 'company': 'Dynamo AI', 'location': 'London, England, United Kingdom', 'url': 'https://uk.linkedin.com/jobs/view/ml-research-engineer-%E2%80%94-natural-language-processing-at-dynamo-ai-4005664651?position=9&pageNum=0&refId=xHXMNW9Pvvzf%2FgSYQUOBIA%3D%3D&trackingId=jr5cnZive1KM2gilWynQjw%3D%3D', 'description': \"Dynamo AI , believe LLMs must developed safety , privacy , real-world responsibility mind . ML team comes culture academic research driven democratize AI advancements responsibly . operating intersection ML research industry applications , team empowers Fortune 500 companies â€™ adoption frontier research next generation LLM products.As Machine Learning Engineer - NLP , design , develop , maintain ML code products centered around LLM safety privacy.Join us : Wish work premier platform AI safety , compliance privacy . provide fastest end end solution deploy research real world fast-paced team ML Ph.D. â€™ builders , free Big Tech / academic bureaucracy constraintsAre excited idea democratizing productionizing state-of-the-art research safe responsible AIWish work scaling robustifying Dynamo AI â€™ products intelligent designs rigorous implementationsAre motivated work 2023 CB Insights Top 100 AI Startup see impact end customers timeframe weeks yearsCare building platform empower fair , unbiased , responsible development LLMs â€™ accept status quo sacrificing user safety sake ML advancementResponsibilitiesBe responsible vertical Dynamo AI â€™ state-of-the-art safety guardrailsPerform rigorous testing product features ensure seamless integrations customers â€™ AI workflowsPush envelope implementing novel techniques delivers world â€™ performing models . work directly empower customers feasibly deploy safe responsible LLMsWork closely policy , product , engineering teams ship features customersQualificationsDeep domain knowledge Natural Language Processing , especially entity recognition tasksExtensive experience designing , implementing , maintaining production-ready ML codePast experience leading end-to-end NLP feature . Including problem formulation , data gathering , training benchmarking/quality assuranceAdaptability flexibility . academic startup world , new finding community may necessitate abrupt shift focus . must able learn , implement , extend state-of-the-art research short time-framesPreferred : Past experience NER PII detection and/or synthetic data generationDynamo AI committed maintaining compliance applicable local state laws regarding job listings salary transparency . includes adhering specific regulations mandate disclosure salary ranges job postings upon request hiring process . strive ensure practices promote fairness , equity , transparency candidates.Salary position may vary based several factors , including candidate 's experience , expertise , geographic location role . Compensation determined ensure competitiveness equity , reflecting cost living different regions specific skills qualifications candidate .\"}\n",
      "{'title': 'Data Scientist - Work From Home', 'company': 'Outlier', 'location': 'Slough, England, United Kingdom', 'url': 'https://uk.linkedin.com/jobs/view/data-scientist-work-from-home-at-outlier-4181842055?position=10&pageNum=0&refId=xHXMNW9Pvvzf%2FgSYQUOBIA%3D%3D&trackingId=Qv7TB8UCSAWvk6Jq5DdKeA%3D%3D', 'description': \"AboutOutlier helps world â€™ innovative companies improve AI models providing human feedback . experienced Math Expert would like lend expertise train AI models ? opportunity : Outlier looking talented Math Experts help train generative artificial intelligence modelsThis freelance opportunity remote hours flexible , work whenever best youYou may contribute expertise byâ€¦ Assessing factuality relevance domain-specific text produced AI modelsCrafting answering questions related MathEvaluating ranking domain-specific responses generated AI models Examples desirable expertise : Master 's higher degree Math related subjectExperience working Math professionalAbility write clearly concepts related Math fluent EnglishPayment : Currently , pay rates core project work Math experts UK range $ 30 $ 50 USD per hourRates vary based expertise , skills assessment , location , project need , factors . example , higher rates may offered PhDs . non-core work , initial project onboarding project overtime phases , lower rates may apply . Certain projects offer incentive payments . Please review payment terms project .\"}\n"
     ]
    }
   ],
   "source": [
    "### Rate limiting function.\n",
    "\n",
    "# Function to scrape the job descriptions.\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"Remove stopwords from a given text using NLTK.\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "def scrape_jobs_with_descriptions(keywords, location, f_WT, pages_to_scrape, headers):\n",
    "    keywords_encoded = quote(keywords)\n",
    "    location_encoded = quote(location)\n",
    "    jobs = []\n",
    "\n",
    "    for page in range(pages_to_scrape):\n",
    "        # LinkedIn URL for job search\n",
    "        url = f\"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords={keywords_encoded}&location={location_encoded}&f_WT={f_WT}&start={25 * page}\"\n",
    "        print(f\"Scraping job list page: {url}\")\n",
    "\n",
    "        # Make a GET request\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch page {page + 1}: {response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        # Parse the HTML\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        divs = soup.find_all(\"div\", class_=\"base-card\")\n",
    "\n",
    "        for div in divs:\n",
    "            try:\n",
    "                # Extract job title, company, location\n",
    "                title = div.find(\"h3\", class_=\"base-search-card__title\").text.strip()\n",
    "                company = div.find(\"h4\", class_=\"base-search-card__subtitle\").text.strip()\n",
    "                location = div.find(\"span\", class_=\"job-search-card__location\").text.strip()\n",
    "\n",
    "                # Extract the job URL from the <a> tag with the class \"base-card__full-link\"\n",
    "                job_link_tag = div.find(\"a\", class_=\"base-card__full-link\")\n",
    "                job_url = job_link_tag[\"href\"] if job_link_tag else \"No URL found\"\n",
    "\n",
    "                # Fetch the job description from the job URL\n",
    "                job_description = fetch_job_description(job_url, headers) if job_url != \"No URL found\" else \"No description available\"\n",
    "                job_description = remove_stopwords(job_description)\n",
    "\n",
    "                # Add job details to the list\n",
    "                jobs.append({\n",
    "                    \"title\": title,\n",
    "                    \"company\": company,\n",
    "                    \"location\": location,\n",
    "                    \"url\": job_url,\n",
    "                    \"description\": job_description\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing job: {e}\")\n",
    "\n",
    "        ### RATE LIMIT ADDED: Pause for 2 seconds after processing each page\n",
    "        time.sleep(2)\n",
    "\n",
    "    return jobs\n",
    "\n",
    "def fetch_job_description(job_url, headers):\n",
    "    \"\"\"Fetch job description from individual job posting.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(job_url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch job page: {job_url}\")\n",
    "            return \"Failed to fetch job description\"\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        description_div = soup.find(\"div\", class_=\"show-more-less-html__markup\")\n",
    "        if description_div:\n",
    "            return description_div.get_text(strip=True).replace(\"\\n\", \" \")\n",
    "        return \"No description available\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching job description: {e}\")\n",
    "        return \"Error fetching job description\"\n",
    "\n",
    "# Configuration\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "keywords = \"Data Scientist\"\n",
    "location = \"London\"\n",
    "f_WT = \"2\"  # Remote jobs\n",
    "pages_to_scrape = 1  # Number of pages to scrape\n",
    "\n",
    "# Run the scraper and store the results in a list of dictionaries. Each entry includes:\n",
    "jobs_with_descriptions = scrape_jobs_with_descriptions(keywords, location, f_WT, pages_to_scrape, headers)\n",
    "\n",
    "# Print job details\n",
    "for job in jobs_with_descriptions:\n",
    "    print(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping job list page: https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Data%20Scientist&location=London&f_WT=2&start=0\n",
      "Scraping job list page: https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Data%20Scientist&location=London&f_WT=2&start=25\n",
      "Failed to fetch job page: https://uk.linkedin.com/jobs/view/principal-decision-scientist-applied-optimization-and-simulation-2025-uk-at-aimpoint-digital-4162470234?position=1&pageNum=2&refId=z%2BOXi99qogCAYKv71HPl%2Bg%3D%3D&trackingId=rIkMByoXGsmsQAL4MlDIrA%3D%3D\n",
      "Failed to fetch job page: https://uk.linkedin.com/jobs/view/ai-developer-amp-pound-50-000-remote-at-tenth-revolution-group-4182366827?position=2&pageNum=2&refId=z%2BOXi99qogCAYKv71HPl%2Bg%3D%3D&trackingId=tfBePxkOMjWCyyrklBiZFQ%3D%3D\n",
      "Failed to fetch job page: https://uk.linkedin.com/jobs/view/ai-software-engineer-at-siena-ai-4051717334?position=3&pageNum=2&refId=z%2BOXi99qogCAYKv71HPl%2Bg%3D%3D&trackingId=qeY9TV4kECdhUxg1ghb%2Bxw%3D%3D\n",
      "Failed to fetch job page: https://uk.linkedin.com/jobs/view/research-scientist-large-language-model-post-training-at-polyai-4182629066?position=4&pageNum=2&refId=z%2BOXi99qogCAYKv71HPl%2Bg%3D%3D&trackingId=n7N02vwyZ7Ce9mbWZc7FOw%3D%3D\n",
      "Failed to fetch job page: https://uk.linkedin.com/jobs/view/senior-decision-scientist-at-monzo-bank-4086257871?position=5&pageNum=2&refId=z%2BOXi99qogCAYKv71HPl%2Bg%3D%3D&trackingId=dPowrM1W%2Be2fk3Am0%2FTMtA%3D%3D\n",
      "Scraping job list page: https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Data%20Scientist&location=London&f_WT=2&start=50\n",
      "Failed to fetch job page: https://uk.linkedin.com/jobs/view/senior-machine-learning-engineer-at-harnham-4171840891?position=5&pageNum=5&refId=J7QmtR1UwQDHdd67bDq7tQ%3D%3D&trackingId=FX8q5B6KHCjumS82RHqrdw%3D%3D\n",
      "Failed to fetch job page: https://uk.linkedin.com/jobs/view/senior-machine-learning-engineer-at-harnham-4168490190?position=6&pageNum=5&refId=J7QmtR1UwQDHdd67bDq7tQ%3D%3D&trackingId=FLI8%2FKf0UZNOmgmwMMUpzw%3D%3D\n",
      "Failed to fetch job page: https://uk.linkedin.com/jobs/view/senior-machine-learning-ops-engineer-at-dailypay-4184855065?position=7&pageNum=5&refId=J7QmtR1UwQDHdd67bDq7tQ%3D%3D&trackingId=tdjjupcxvrwIliqGD2pQOQ%3D%3D\n",
      "Failed to fetch job page: https://uk.linkedin.com/jobs/view/junior-backend-engineer-at-verisian-4180424821?position=8&pageNum=5&refId=J7QmtR1UwQDHdd67bDq7tQ%3D%3D&trackingId=wN5B9ki%2BureDrosw8YhHDA%3D%3D\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m pages_to_scrape \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m  \u001b[38;5;66;03m# Number of pages to scrape\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Run the scraper and stores it in a list of dictionaries. Each entry includes:\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m jobs_with_descriptions \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_jobs_with_descriptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_WT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpages_to_scrape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Print job details\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m jobs_with_descriptions:\n",
      "Cell \u001b[0;32mIn[5], line 42\u001b[0m, in \u001b[0;36mscrape_jobs_with_descriptions\u001b[0;34m(keywords, location, f_WT, pages_to_scrape, headers)\u001b[0m\n\u001b[1;32m     39\u001b[0m job_url \u001b[38;5;241m=\u001b[39m job_link_tag[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m job_link_tag \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo URL found\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Fetch the job description from the job URL\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m job_description \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_job_description\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m job_url \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo URL found\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo description available\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m job_description \u001b[38;5;241m=\u001b[39m remove_stopwords(job_description)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Add job details to the list\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 62\u001b[0m, in \u001b[0;36mfetch_job_description\u001b[0;34m(job_url, headers)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fetch job description from individual job posting.\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to fetch job page: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/github/linkedin/linkedin_env/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/github/linkedin/linkedin_env/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/github/linkedin/linkedin_env/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Desktop/github/linkedin/linkedin_env/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Desktop/github/linkedin/linkedin_env/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Desktop/github/linkedin/linkedin_env/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/github/linkedin/linkedin_env/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/Desktop/github/linkedin/linkedin_env/lib/python3.12/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Original.\n",
    "\n",
    "# Function to scrape the job descriptions.\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"Remove stopwords from a given text using NLTK.\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "def scrape_jobs_with_descriptions(keywords, location, f_WT, pages_to_scrape, headers):\n",
    "    keywords_encoded = quote(keywords)\n",
    "    location_encoded = quote(location)\n",
    "    jobs = []\n",
    "\n",
    "    for page in range(pages_to_scrape):\n",
    "        # LinkedIn URL for job search\n",
    "        url = f\"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords={keywords_encoded}&location={location_encoded}&f_WT={f_WT}&start={25 * page}\"\n",
    "        print(f\"Scraping job list page: {url}\")\n",
    "\n",
    "        # Make a GET request\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch page {page + 1}: {response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        # Parse the HTML\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        divs = soup.find_all(\"div\", class_=\"base-card\")\n",
    "\n",
    "        for div in divs:\n",
    "            try:\n",
    "                # Extract job title, company, location\n",
    "                title = div.find(\"h3\", class_=\"base-search-card__title\").text.strip()\n",
    "                company = div.find(\"h4\", class_=\"base-search-card__subtitle\").text.strip()\n",
    "                location = div.find(\"span\", class_=\"job-search-card__location\").text.strip()\n",
    "\n",
    "                # Extract the job URL from the <a> tag with the class \"base-card__full-link\"\n",
    "                job_link_tag = div.find(\"a\", class_=\"base-card__full-link\")\n",
    "                job_url = job_link_tag[\"href\"] if job_link_tag else \"No URL found\"\n",
    "\n",
    "                # Fetch the job description from the job URL\n",
    "                job_description = fetch_job_description(job_url, headers) if job_url != \"No URL found\" else \"No description available\"\n",
    "                job_description = remove_stopwords(job_description)\n",
    "\n",
    "\n",
    "                # Add job details to the list\n",
    "                jobs.append({\n",
    "                    \"title\": title,\n",
    "                    \"company\": company,\n",
    "                    \"location\": location,\n",
    "                    \"url\": job_url,\n",
    "                    \"description\": job_description\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing job: {e}\")\n",
    "\n",
    "    return jobs\n",
    "\n",
    "def fetch_job_description(job_url, headers):\n",
    "    \"\"\"Fetch job description from individual job posting.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(job_url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch job page: {job_url}\")\n",
    "            return \"Failed to fetch job description\"\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        description_div = soup.find(\"div\", class_=\"show-more-less-html__markup\")\n",
    "        if description_div:\n",
    "            return description_div.get_text(strip=True).replace(\"\\n\", \" \")\n",
    "        return \"No description available\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching job description: {e}\")\n",
    "        return \"Error fetching job description\"\n",
    "\n",
    "# Configuration\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "keywords = \"Data Scientist\"\n",
    "location = \"London\"\n",
    "f_WT = \"2\"  # Remote jobs\n",
    "pages_to_scrape = 20  # Number of pages to scrape\n",
    "\n",
    "# Run the scraper and stores it in a list of dictionaries. Each entry includes:\n",
    "jobs_with_descriptions = scrape_jobs_with_descriptions(keywords, location, f_WT, pages_to_scrape, headers)\n",
    "\n",
    "# Print job details\n",
    "for job in jobs_with_descriptions:\n",
    "    print(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_tokenize((jobs_with_descriptions[0]['description'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jobs_with_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"border: 1px solid #ddd; padding: 15px; border-radius: 5px; margin: 10px 0;\n",
       "            font-family: Arial, sans-serif; line-height: 1.6; white-space: pre-wrap; background-color: #f9f9f9;\">\n",
       "    <h3 style=\"margin-top: 0; font-size: 16px; color: #333;\">Job Description</h3>\n",
       "    <p style=\"margin: 0;\">Data TeamProlificProlific another player AI space â€“ architects human data infrastructure 's reshaping landscape AI development . world foundational AI technologies increasingly commoditized , 's quality diversity human-generated data truly differentiates products models.The roleWe 're looking Data Scientist strong analytical skills passion solving complex problems join team . 'll work cross-functionally product engineering teams , driving initiatives unlock power vast datasets . 'll significant autonomy design , build , deploy models , develop measurement frameworks , help influence decisions directly impact platform 's capabilities business strategy . data function supports multiple areas business , giving exposure diverse challenges allowing develop deep expertise specific domains based interests business priorities.What 'll bring roleExperience interest working human behavioral data , annotation/labeling systems , projects involving human feedback AI development evaluationExperience building measurement systems analytical frameworks , experimental design , causal inference methods , multi-dimensional evaluation metricsProficiency working modern foundation models understanding leverage versus traditional ML approachesSolid software engineering fundamentals expertise Python/R , SQL , AI/ML frameworks , modern data science stackA toolkit spanning classical statistical methods state-of-the-art ML techniques , knowledge choose apply right tool unique problemProven ability effectively communicate influence stakeholders across organization , engineers executivesAbility thrive fast-paced environments balance speed qualityStrong prioritization skills , consistently focusing high-impact workWhat 'll roleDevelop implement sophisticated models algorithms assess improve quality integrity human data platformCollaborate closely product managers engineers identify opportunities data science drive product innovation user valueSynthesize complex analyses actionable insights , presenting compelling data-driven narratives influence strategic decisionsEvaluate implement cutting-edge data science methodologies tools , ensuring team stays forefront fieldPartner data engineers enhance data pipelines , logging systems , MLOps practices , creating robust foundation advanced analytics modelingWhy Prolific great place workWe 've built unique platform connects researchers companies global pool participants , enabling collection high-quality , ethically sourced human behavioral data feedback . data cornerstone developing accurate , nuanced , aligned AI systems.We believe next leap AI capabilities wo n't come solely scaling existing models , integrating diverse human perspectives behaviors AI development . providing crucial human data infrastructure , Prolific positioning forefront next wave AI innovation â€“ one reflects breath best humanity.Working us place forefront AI innovation , providing access unique human data platform opportunities groundbreaking research . Join us enjoy competitive salary , benefits , remote working within impactful , mission-driven culture.Links information ProlificBenefitsExternal HandbookWebsiteYoutubePrivacy StatementBy submitting application , agree Prolific may collect personal data recruiting global organisation planning . Prolific 's Candidate Privacy Notice explains personal information Prolific may process , Prolific may process personal information , purposes processing personal information , rights exercise Prolific use personal information .</p>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Display the first job description in a styled block\n",
    "description = jobs_with_descriptions[0]['description']\n",
    "html_block = f\"\"\"\n",
    "<div style=\"border: 1px solid #ddd; padding: 15px; border-radius: 5px; margin: 10px 0;\n",
    "            font-family: Arial, sans-serif; line-height: 1.6; white-space: pre-wrap; background-color: #f9f9f9;\">\n",
    "    <h3 style=\"margin-top: 0; font-size: 16px; color: #333;\">Job Description</h3>\n",
    "    <p style=\"margin: 0;\">{description}</p>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_block))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Data TeamProlificProlific another player AI space â€“ architects human data infrastructure 's reshaping landscape AI development . world foundational AI technologies increasingly commoditized , 's quality diversity human-generated data truly differentiates products models.The roleWe 're looking Data Scientist strong analytical skills passion solving complex problems join team . 'll work cross-functionally product engineering teams , driving initiatives unlock power vast datasets . 'll significant autonomy design , build , deploy models , develop measurement frameworks , help influence decisions directly impact platform 's capabilities business strategy . data function supports multiple areas business , giving exposure diverse challenges allowing develop deep expertise specific domains based interests business priorities.What 'll bring roleExperience interest working human behavioral data , annotation/labeling systems , projects involving human feedback AI development evaluationExperience building measurement systems analytical frameworks , experimental design , causal inference methods , multi-dimensional evaluation metricsProficiency working modern foundation models understanding leverage versus traditional ML approachesSolid software engineering fundamentals expertise Python/R , SQL , AI/ML frameworks , modern data science stackA toolkit spanning classical statistical methods state-of-the-art ML techniques , knowledge choose apply right tool unique problemProven ability effectively communicate influence stakeholders across organization , engineers executivesAbility thrive fast-paced environments balance speed qualityStrong prioritization skills , consistently focusing high-impact workWhat 'll roleDevelop implement sophisticated models algorithms assess improve quality integrity human data platformCollaborate closely product managers engineers identify opportunities data science drive product innovation user valueSynthesize complex analyses actionable insights , presenting compelling data-driven narratives influence strategic decisionsEvaluate implement cutting-edge data science methodologies tools , ensuring team stays forefront fieldPartner data engineers enhance data pipelines , logging systems , MLOps practices , creating robust foundation advanced analytics modelingWhy Prolific great place workWe 've built unique platform connects researchers companies global pool participants , enabling collection high-quality , ethically sourced human behavioral data feedback . data cornerstone developing accurate , nuanced , aligned AI systems.We believe next leap AI capabilities wo n't come solely scaling existing models , integrating diverse human perspectives behaviors AI development . providing crucial human data infrastructure , Prolific positioning forefront next wave AI innovation â€“ one reflects breath best humanity.Working us place forefront AI innovation , providing access unique human data platform opportunities groundbreaking research . Join us enjoy competitive salary , benefits , remote working within impactful , mission-driven culture.Links information ProlificBenefitsExternal HandbookWebsiteYoutubePrivacy StatementBy submitting application , agree Prolific may collect personal data recruiting global organisation planning . Prolific 's Candidate Privacy Notice explains personal information Prolific may process , Prolific may process personal information , purposes processing personal information , rights exercise Prolific use personal information .\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_with_descriptions[0]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try it with one job description\n",
    "\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=GEM_KEY)\n",
    "\n",
    "# prompt = (\n",
    "#     f\"Extract the relevant hard skills and soft skills from the following job description: {jobs_with_descriptions[0]['description']}. \"\n",
    "#     \"Return only a valid JSON object with exactly two keys: 'hard_skills' and 'soft_skills', where each key maps to an array of strings. \"\n",
    "#     \"Ensure you only output the JSON object in the following format (example): {{\\\"hard_skills\\\": [\\\"skill1\\\", \\\"skill2\\\"], \\\"soft_skills\\\": [\\\"skillA\\\", \\\"skillB\\\"]}}. \"\n",
    "#     \"Do not include any markdown formatting, triple backticks, or any extra text. Only output the JSON object.\"\n",
    "# )\n",
    "\n",
    "prompt = f'''Extract the relevant hard skills and soft skills from the following job description. For hard skills, make sure to include programming languages, libraries, technologies mentioned.\n",
    "            Return only a valid JSON object with exactly two keys: 'hard_skills' and 'soft_skills', where each key maps to an array of strings. Ensure you only output the JSON object in the following format (example): {{\\\"hard_skills\\\": [\\\"skill1\\\", \\\"skill2\\\"], \\\"soft_skills\\\": [\\\"skillA\\\", \\\"skillB\\\"]}}. Do not include any markdown formatting, triple backticks, or any extra text. Only output the JSON object.)\n",
    "            # Description: {jobs_with_descriptions[0]['description']}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"hard_skills\": [\\n    \"Python\",\\n    \"R\",\\n    \"SQL\",\\n    \"AI/ML frameworks\",\\n    \"modern data science stack\",\\n    \"MLOps\",\\n    \"experimental design\",\\n    \"causal inference methods\",\\n    \"statistical methods\"\\n  ],\\n  \"soft_skills\": [\\n    \"analytical skills\",\\n    \"communication\",\\n    \"influence\",\\n    \"prioritization\",\\n    \"problem-solving\",\\n    \"collaboration\"\\n  ]\\n}\\n```'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Available models:\n",
    "# model='gemini-2.0-flash-lite-preview-02-05',\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt)\n",
    "\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Hard Skills:\n",
      "                             Skill  Frequency\n",
      "0                           python          6\n",
      "1                                r          2\n",
      "2                              sql          3\n",
      "3                 ai/ml frameworks          1\n",
      "4        modern data science stack          1\n",
      "5    classical statistical methods          1\n",
      "6   state-of-the-art ml techniques          1\n",
      "7                            mlops          1\n",
      "8                       statistics          1\n",
      "9                     data science          1\n",
      "10             operations research          1\n",
      "11          statistical techniques          1\n",
      "12     machine learning techniques          2\n",
      "13                      clustering          2\n",
      "14                      regression          1\n",
      "15                  decision trees          1\n",
      "16                      databricks          1\n",
      "17                           spark          1\n",
      "18                         pyspark          1\n",
      "19                          pandas          2\n",
      "20                           numpy          2\n",
      "21                           scipy          1\n",
      "22            statistical modeling          1\n",
      "23            software engineering          1\n",
      "24                 version control          1\n",
      "25                      unit tests          1\n",
      "26                    code reviews          1\n",
      "27                           ci/cd          1\n",
      "28                              go          1\n",
      "29                             c++          1\n",
      "30                            java          1\n",
      "31                          docker          1\n",
      "32                      kubernetes          1\n",
      "33                      tensorflow          3\n",
      "34                         pytorch          3\n",
      "35                             dbt          1\n",
      "36          decision tree learning          1\n",
      "37      artificial neural networks          1\n",
      "38                             llm          1\n",
      "39                             vlm          1\n",
      "40              cloud technologies          1\n",
      "41                containerization          1\n",
      "42                             nlp          1\n",
      "43                             ner          1\n",
      "44                   pii detection          1\n",
      "\n",
      "Aggregated Soft Skills:\n",
      "                             Skill  Frequency\n",
      "0                analytical skills          2\n",
      "1                    communication          9\n",
      "2                        influence          1\n",
      "3                   prioritization          1\n",
      "4                  problem-solving          5\n",
      "5   cross-functional collaboration          1\n",
      "6                         research          1\n",
      "7                 project planning          1\n",
      "8                      data mining          1\n",
      "9                        analytics          1\n",
      "10                   collaboration          5\n",
      "11                    independence          1\n",
      "12              project management          1\n",
      "13                 line management          1\n",
      "14                        coaching          1\n",
      "15                      leadership          1\n",
      "16                 approachability          1\n",
      "17                      pragmatism          1\n",
      "18          analytical experiments          1\n",
      "19                 problem solving          1\n",
      "20                 time management          1\n",
      "21                            math          2\n",
      "22                         writing          2\n",
      "23               strategic mindset          1\n",
      "24                    adaptability          1\n",
      "25                     flexibility          1\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "import json\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Initialize the Gemini client\n",
    "client = genai.Client(api_key=GEM_KEY)\n",
    "\n",
    "def clean_json_output(response_text):\n",
    "    \"\"\"\n",
    "    Remove markdown formatting (triple backticks and '```json' label)\n",
    "    and return a clean JSON string.\n",
    "    \"\"\"\n",
    "    response_text = response_text.strip()\n",
    "    if response_text.startswith(\"```json\"):\n",
    "        response_text = response_text[len(\"```json\"):].strip()\n",
    "    if response_text.endswith(\"```\"):\n",
    "        response_text = response_text[:-len(\"```\")].strip()\n",
    "    return response_text\n",
    "\n",
    "def batch_jobs(jobs, batch_size):\n",
    "    \"\"\"Yield successive batches from the jobs list.\"\"\"\n",
    "    for i in range(0, len(jobs), batch_size):\n",
    "        yield jobs[i:i + batch_size]\n",
    "\n",
    "extracted_skills = []\n",
    "\n",
    "# ----- UPDATED CODE: Batch Size Calculation -----\n",
    "# Assuming pages_to_scrape is 10 (as defined earlier) and jobs are evenly distributed:\n",
    "jobs_per_page = len(jobs_with_descriptions) // pages_to_scrape\n",
    "batch_size = jobs_per_page * 2  # Two pages per batch\n",
    "# ----- END OF UPDATED CODE -----\n",
    "\n",
    "for batch in batch_jobs(jobs_with_descriptions, batch_size):\n",
    "    # Combine the job descriptions using a clear delimiter.\n",
    "    descriptions = \"\\n---\\n\".join(job['description'] for job in batch)\n",
    "    prompt = (\n",
    "        \"Below are several job descriptions separated by '---'. \"\n",
    "        \"For each job description, extract the relevant hard skills and soft skills. \"\n",
    "        \"For hard skills, include programming languages, libraries, and technologies mentioned. \"\n",
    "        \"Return a JSON array where each element is an object with exactly two keys: \"\n",
    "        \"'hard_skills' and 'soft_skills', mapping to arrays of strings. \"\n",
    "        \"Only output the JSON array with no extra text or markdown formatting.\\n\\n\" +\n",
    "        descriptions\n",
    "    )\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        # model='gemini-2.0-flash-lite-preview-02-05',\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "\n",
    "    cleaned = clean_json_output(response.text)\n",
    "\n",
    "    try:\n",
    "        # Expecting a JSON array with one element per job description in the batch\n",
    "        batch_parsed = json.loads(cleaned)\n",
    "\n",
    "        # Optional: Check if the parsed array has the same number of elements as the batch.\n",
    "        if not isinstance(batch_parsed, list) or len(batch_parsed) != len(batch):\n",
    "            print(\"Warning: The parsed output count does not match the number of job descriptions in the batch.\")\n",
    "\n",
    "        # Normalize skills to lowercase for consistency.\n",
    "        for job_skills in batch_parsed:\n",
    "            if \"hard_skills\" in job_skills:\n",
    "                job_skills[\"hard_skills\"] = [skill.lower() for skill in job_skills[\"hard_skills\"]]\n",
    "            if \"soft_skills\" in job_skills:\n",
    "                job_skills[\"soft_skills\"] = [skill.lower() for skill in job_skills[\"soft_skills\"]]\n",
    "        extracted_skills.extend(batch_parsed)\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing batched JSON:\", e)\n",
    "\n",
    "# Aggregate the skills across all processed job descriptions.\n",
    "hard_skills_counter = Counter()\n",
    "soft_skills_counter = Counter()\n",
    "\n",
    "for skills in extracted_skills:\n",
    "    if \"hard_skills\" in skills:\n",
    "        hard_skills_counter.update(skills[\"hard_skills\"])\n",
    "    if \"soft_skills\" in skills:\n",
    "        soft_skills_counter.update(skills[\"soft_skills\"])\n",
    "\n",
    "# Create DataFrames for visualization.\n",
    "df_hard = pd.DataFrame(hard_skills_counter.items(), columns=[\"Skill\", \"Frequency\"])\n",
    "df_soft = pd.DataFrame(soft_skills_counter.items(), columns=[\"Skill\", \"Frequency\"])\n",
    "\n",
    "print(\"Aggregated Hard Skills:\")\n",
    "print(df_hard)\n",
    "print(\"\\nAggregated Soft Skills:\")\n",
    "print(df_soft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Hard Skill=%{x}<br>Count=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": {
           "bdata": "BgMDAwICAgICAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEB",
           "dtype": "i1"
          },
          "coloraxis": "coloraxis",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "python",
          "sql",
          "tensorflow",
          "pytorch",
          "clustering",
          "r",
          "numpy",
          "pandas",
          "machine learning techniques",
          "artificial neural networks",
          "decision tree learning",
          "dbt",
          "code reviews",
          "llm",
          "vlm",
          "cloud technologies",
          "kubernetes",
          "docker",
          "java",
          "containerization",
          "nlp",
          "c++",
          "ner",
          "go",
          "ci/cd",
          "statistical modeling",
          "unit tests",
          "operations research",
          "ai/ml frameworks",
          "modern data science stack",
          "classical statistical methods",
          "state-of-the-art ml techniques",
          "mlops",
          "statistics",
          "data science",
          "statistical techniques",
          "version control",
          "regression",
          "decision trees",
          "databricks",
          "spark",
          "pyspark",
          "scipy",
          "software engineering",
          "pii detection"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "BgMDAwICAgICAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEB",
          "dtype": "i1"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Count"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Top Hard Skills"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "tickangle": -45,
         "title": {
          "text": "Hard Skill"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Soft Skill=%{x}<br>Count=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": {
           "bdata": "CQUFAgICAQEBAQEBAQEBAQEBAQEBAQEBAQE=",
           "dtype": "i1"
          },
          "coloraxis": "coloraxis",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "communication",
          "problem-solving",
          "collaboration",
          "analytical skills",
          "writing",
          "math",
          "leadership",
          "adaptability",
          "strategic mindset",
          "time management",
          "problem solving",
          "analytical experiments",
          "pragmatism",
          "approachability",
          "line management",
          "coaching",
          "project management",
          "independence",
          "analytics",
          "data mining",
          "project planning",
          "research",
          "cross-functional collaboration",
          "prioritization",
          "influence",
          "flexibility"
         ],
         "xaxis": "x",
         "y": {
          "bdata": "CQUFAgICAQEBAQEBAQEBAQEBAQEBAQEBAQE=",
          "dtype": "i1"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Count"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Top Soft Skills"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "tickangle": -45,
         "title": {
          "text": "Soft Skill"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization with Plotly.\n",
    "df_hard_sorted = df_hard.sort_values(\"Frequency\", ascending=False)\n",
    "df_soft_sorted = df_soft.sort_values(\"Frequency\", ascending=False)\n",
    "\n",
    "fig_hard = px.bar(\n",
    "    df_hard_sorted,\n",
    "    x=\"Skill\",\n",
    "    y=\"Frequency\",\n",
    "    title=\"Top Hard Skills\",\n",
    "    labels={\"Skill\": \"Hard Skill\", \"Frequency\": \"Count\"},\n",
    "    color=\"Frequency\",\n",
    "    color_continuous_scale=\"Blues\"\n",
    ")\n",
    "fig_hard.update_layout(xaxis_tickangle=-45)\n",
    "fig_hard.show()\n",
    "\n",
    "fig_soft = px.bar(\n",
    "    df_soft_sorted,\n",
    "    x=\"Skill\",\n",
    "    y=\"Frequency\",\n",
    "    title=\"Top Soft Skills\",\n",
    "    labels={\"Skill\": \"Soft Skill\", \"Frequency\": \"Count\"},\n",
    "    color=\"Frequency\",\n",
    "    color_continuous_scale=\"Blues\"\n",
    ")\n",
    "fig_soft.update_layout(xaxis_tickangle=-45)\n",
    "fig_soft.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sql</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>clustering</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>numpy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pandas</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>machine learning techniques</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>artificial neural networks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>decision tree learning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>dbt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>code reviews</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>llm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>vlm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>cloud technologies</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>kubernetes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>docker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>java</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>containerization</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>nlp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>c++</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>go</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ci/cd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>statistical modeling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>unit tests</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>operations research</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ai/ml frameworks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>modern data science stack</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>classical statistical methods</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>state-of-the-art ml techniques</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mlops</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>statistics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data science</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>statistical techniques</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>version control</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>regression</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>decision trees</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>databricks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>spark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pyspark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>scipy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>software engineering</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>pii detection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Skill  Frequency\n",
       "0                           python          6\n",
       "2                              sql          3\n",
       "33                      tensorflow          3\n",
       "34                         pytorch          3\n",
       "13                      clustering          2\n",
       "1                                r          2\n",
       "20                           numpy          2\n",
       "19                          pandas          2\n",
       "12     machine learning techniques          2\n",
       "37      artificial neural networks          1\n",
       "36          decision tree learning          1\n",
       "35                             dbt          1\n",
       "26                    code reviews          1\n",
       "38                             llm          1\n",
       "39                             vlm          1\n",
       "40              cloud technologies          1\n",
       "32                      kubernetes          1\n",
       "31                          docker          1\n",
       "30                            java          1\n",
       "41                containerization          1\n",
       "42                             nlp          1\n",
       "29                             c++          1\n",
       "43                             ner          1\n",
       "28                              go          1\n",
       "27                           ci/cd          1\n",
       "22            statistical modeling          1\n",
       "25                      unit tests          1\n",
       "10             operations research          1\n",
       "3                 ai/ml frameworks          1\n",
       "4        modern data science stack          1\n",
       "5    classical statistical methods          1\n",
       "6   state-of-the-art ml techniques          1\n",
       "7                            mlops          1\n",
       "8                       statistics          1\n",
       "9                     data science          1\n",
       "11          statistical techniques          1\n",
       "24                 version control          1\n",
       "14                      regression          1\n",
       "15                  decision trees          1\n",
       "16                      databricks          1\n",
       "17                           spark          1\n",
       "18                         pyspark          1\n",
       "21                           scipy          1\n",
       "23            software engineering          1\n",
       "44                   pii detection          1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hard_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Skill, Frequency]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hard_sorted[df_hard_sorted['Skill'].str.contains('aws', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>communication</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>problem-solving</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>collaboration</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>analytical skills</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>writing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>math</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>leadership</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>adaptability</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>strategic mindset</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>time management</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>problem solving</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>analytical experiments</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pragmatism</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>approachability</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>line management</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>coaching</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>project management</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>independence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>analytics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data mining</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>project planning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>research</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cross-functional collaboration</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prioritization</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>influence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>flexibility</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Skill  Frequency\n",
       "1                    communication          9\n",
       "4                  problem-solving          5\n",
       "10                   collaboration          5\n",
       "0                analytical skills          2\n",
       "22                         writing          2\n",
       "21                            math          2\n",
       "15                      leadership          1\n",
       "24                    adaptability          1\n",
       "23               strategic mindset          1\n",
       "20                 time management          1\n",
       "19                 problem solving          1\n",
       "18          analytical experiments          1\n",
       "17                      pragmatism          1\n",
       "16                 approachability          1\n",
       "13                 line management          1\n",
       "14                        coaching          1\n",
       "12              project management          1\n",
       "11                    independence          1\n",
       "9                        analytics          1\n",
       "8                      data mining          1\n",
       "7                 project planning          1\n",
       "6                         research          1\n",
       "5   cross-functional collaboration          1\n",
       "3                   prioritization          1\n",
       "2                        influence          1\n",
       "25                     flexibility          1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_soft_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Let's try DeepSeek, especially it's output.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> 5\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEEP_KEY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://api.deepseek.com\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      8\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepseek-chat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/Desktop/github/linkedin/linkedin_env/lib/python3.12/site-packages/openai/_client.py:110\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    108\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Let's try DeepSeek, especially it's output.\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=DEEP_KEY, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# API not working at the moment..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping job list page: https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=software%20engineer&location=Remote&f_WT=2&start=0\n",
      "{'title': 'Software Engineer', 'company': 'Microsoft', 'location': 'Bengaluru, Karnataka, India', 'url': 'https://in.linkedin.com/jobs/view/software-engineer-at-microsoft-4131147250?position=1&pageNum=0&refId=gwJNwjrnv3xMXSUwJOU0kg%3D%3D&trackingId=25mdpDh2rGiqMrW%2BLBFqXQ%3D%3D', 'description': \"Have you ever imagined a world with an infinite amount of storage available and accessible to everyone? A place where everyone in the world can easily access their data from anywhere at any time via any means (e.g., mobile phones, tablets, PCs, smart devices, etc.). Did you ever desire a universally accessible storage system to record all the knowledge known to mankind or to store all the data collected from all the scientists in the world for them to collaborate upon? Do you want to be part of a team that strives to bring these to reality?As a Software Engineer in the Azure Storage team, you will build, improve and support highly scalable, performant services that deliver highly reliable, secure and available access to storage for our customers. You will face challenges of monitoring, analyzing, and designing for ever-growing data needs of our customers and for ensuring data privacy, protection and compliance. This opportunity will allow you to develop your technical skills in cloud services and storage, accelerate career growth, and provide an opportunity to work in a highly dynamic, flexible, and globally distributed team.Microsoftâ€™s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.ResponsibilitiesWorks with appropriate stakeholders to determine user requirements for a feature.Contributes to the identification of dependencies, and the development of design documents for a product area with little oversight.Creates and implements code for a product, service, or feature, reusing code as applicable.Contributes to efforts to break down larger work items into smaller work items and provides estimation.Acts as a Designated Responsible Individual (DRI) and guides other engineers by developing and following the playbook, working on call to monitor system/product/service for degradation, downtime, or interruptions, alerting stakeholders about status and initiates actions to restore system/product/service for simple and complex problems when appropriate.Proactively seeks new knowledge and adapts to new trends, technical solutions, and patterns that will improve the availability, reliability, efficiency, observability, and performance of products while also driving consistency in monitoring and operations at scale.QualificationsRequired Qualifications:Bachelor's Degree in Computer Science, or related technical discipline with proven experience coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python.OR equivalent experience.Excellence in software engineering practices.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Computer Science OR related technical field AND 1+ year(s) technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, OR Python.OR Master's Degree in Computer Science or related technical field with proven experience coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python OR equivalent experience.Experience developing large-scale , high availability services.Experience working on large-scale automated deployment systems.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.\", 'extracted_skills': [{'generated_text': 'hard_skills'}]}\n",
      "{'title': 'Software Engineer', 'company': 'Microsoft', 'location': 'Hyderabad, Telangana, India', 'url': 'https://in.linkedin.com/jobs/view/software-engineer-at-microsoft-4138209505?position=2&pageNum=0&refId=gwJNwjrnv3xMXSUwJOU0kg%3D%3D&trackingId=gjmajAXJwlMybNGoJIU7fw%3D%3D', 'description': \"Azure is experiencing unprecedented growth, making it the fastest-growing business in Microsoft's history. It forms the foundation of Microsoft's commercial Cloud Services, distinguishing itself as the only hyper-scale, enterprise-grade cloud solution with a genuine hybrid capability. Azure's continuous momentum is recognized by customers and analysts. Microsoft Azure's primary goal is to become the most trusted, secure, and global cloud while fostering an exceptional work environment.We are a vital part of the Azure Networking team, responsible for the design, construction, and operation of critical foundational network services. These services set Azure apart from competitors and open up new revenue streams. The Cloud buildout is a technically challenging field, involving a complex interplay of device commissioning and service deployments. The increasing demand for new Azure clouds necessitates the creation of scalable, intricate services and tools that expedite cloud buildouts while ensuring high security through role-based access control.As a Software Engineer you will collaborate with a team of skilled engineers to plan, design, and implement distributed services, automation tools, and frameworks that accelerate new cloud buildout and operations. This opportunity will allow you to influence and collaborate with teams both within and outside Microsoft to create end-to-end scenarios and customer-centric products.Microsoftâ€™s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.ResponsibilitiesWorks with appropriate stakeholders to determine user requirements for a set of features.Contributes to the identification of dependencies, and the development of design documents for a product area with little oversight. Creates and implements code for a product, service, or feature, reusing code as applicable.Planning and developing distributed software services, automation tools, and frameworks to expedite new cloud buildout and operations.Promoting the adoption of best engineering practices and processes within and across teams.Contributes to efforts to break down larger work items into smaller work items and provides estimation.Acts as a Designated Responsible Individual (DRI) working on-call to monitor system/product feature/service for degradation, downtime, or interruptions and gains approval to restore system/product/service for simple problems.Remains current in skills by investing time and effort into staying abreast of current developments that will improve the availability, reliability, efficiency, observability, and performance of products while also driving consistency in monitoring and operations at scale.QualificationsRequired Qualifications:Bachelor's Degree in Computer Science, or related technical discipline with proven experience coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or PythonOR equivalent experienceOther RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings:Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud Background Check upon hire/transfer and every two years thereafter.Preferred QualificationsBachelor's Degree in Computer ScienceOR related technical field AND 1+ years technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript,OR PythonOR Master's Degree in Computer Science or related technical field with proven experience coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or PythonOR equivalent experience#azurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.\", 'extracted_skills': [{'generated_text': 'hard_skills'}]}\n",
      "{'title': 'Full-Stack Software Engineer (New graduates: Canada)', 'company': 'Wanderlog', 'location': 'Canada', 'url': 'https://ca.linkedin.com/jobs/view/full-stack-software-engineer-new-graduates-canada-at-wanderlog-4140323578?position=3&pageNum=0&refId=gwJNwjrnv3xMXSUwJOU0kg%3D%3D&trackingId=Jdb%2FDULxCak75o2q8DyzwQ%3D%3D', 'description': 'Warning: if youâ€™re outside of the Americas timezones, unfortunately, weâ€™re only hiring for engineers with at least some timezone overlap.Wanderlog helps make leisure travel easier. We believe that travel makes the world better, and are building tools that lower the bar to it. Our core product, built starting 2019, is a travel planning app (weâ€™re the top-ranked trip planner on iOS and Android), but weâ€™re also helping travelers book hotels (without hidden fees), providing them with information (through various pages on e.g., best attractions, restaurants, etc.), and more.Our founders are twin brothers. Peter worked as an engineer at Stripe and a consultant at McKinsey, and Harry as a product manager at Google. Weâ€™re an engineering and product-driven team: the founders studied computer science at Yale, and have built successful, bootstrapped travel companies (BookWithMatrix and All the Flight Deals) with products people love before starting Wanderlog.We now serve millions of travelers a month, and are a team of 8, including 7 engineers hailing from MIT, the University of Toronto, UC Berkeley, and more; and 1 designer. Weâ€™re a self-sustaining, default-alive startup.We also love traveling. Whether itâ€™s a short hop to Austin, Seattle, or New Orleans; or a longer jaunt to Australia, Hawaii, or Banff National Park (all places the teamâ€™s traveled to in the past year!), travel broadens our horizons, builds empathy, and challenges us to grow. Weâ€™re working to bring these experiences to more of the world.What Youâ€™ll DoAs an engineer, youâ€™ll be responsible for owning portions of the product. Youâ€™ll be expected to:Build new features on our website and mobile app. (Our stack is Javascript (Typescript): modern React on the web, React Native on mobile, and Node.js/Express on the server.)Design and decide what to build based on what would help travelers and drive growth. You wonâ€™t be handed a spec; youâ€™ll be coming up with it!Build data pipelines to crawl, process, and synthesize data from various sources around the web.Write tests and and build out engineering infrastructure. Our code is fully typed (Typescript) and tested.Debug and fix bugs and scale the infrastructure as it grows.Review code written by other engineers.Be fast and nimble: figure out the best way to build new features at lowest cost in time and future technical debt.This position is a full-time role reporting to the cofounders at Wanderlog.What You Might Work OnNew, user-friendly hotel booking interfaces that make finding a place to stay easier.AI-powered tools that read articles and watch videos for you and summarize the places they mention.Improvements to our React Native mobile app so that it runs faster on slower Android phones.A Chrome extension to let travelers quickly compare possible places to visit, airfares, and hotels.Better invite and collaboration tools to encourage people using Wanderlog to get more friends to join them.A better profile page that lets travelers on Wanderlog show off where theyâ€™ve been, see how many people theyâ€™ve helped, and follow other friends and their trips.You May Be a Good Fit If YouAre a Javascript developer comfortable with React and/or React Native.Are a product person: youâ€™ve built products end-to-end before, and really care about the people who use them.Are comfortable with picking up various technologies for the task at hand. We quickly evaluate libraries and tools that could help our product, and variously use Redis, Elasticsearch, and Python as needed too.Are entrepreneurial: excited about joining a small, high-growth team and talking to users, doing product and design, and wearing a variety of hats.Love travel and believe in it as a positive force personally and for the world.Whatâ€™s it like to work here?Weâ€™re an engineering and product-heavy team. Travelâ€™s something everyone does, and we love using the tools we build. A typical weekâ€™s work involves talking to users, prioritizing tasks in Sheets, designing on Figma, and building and shipping them continuously.Our values include putting travelers first, owning the product end-to-end, treating teammates with respect, and moving fast by being smart about what we build and how we build it.We believe in work fitting in with your life. We love travel and believe it rejuvenates us and makes us better people, and have twice annual travel offsites where the goal is to enjoy visiting a new place and collaborate more closely with the team in person.Our hiring processWeâ€™ll first have you do an asynchronous programming challenge. If all goes well, weâ€™ll have a coding interview where you work on a quick program on your laptop in your preferred language. Weâ€™ll then do another coding interview and a full-day virtual onsite.FoundersPeter Xu and Harry Yu are twin brothers. Peter shuttled between Los Angeles, Houston, New York, Tokyo, and Hong Kong as a consultant at McKinsey before settling down at Stripe as a full-stack engineer, where he worked closely with support teams to build tools that made support agentsâ€™ work more productive.Harry worked at Google as a product manager on Hotel Search, Chrome, and finally Google Assistant for the past three, where he was one of the early PMs on the team.Before building Wanderlog, they had built Coursetable (featured in the New York Times) and travel sites All the Flight Deals (a flight deals aggregator) and BookWithMatrix (a power-traveler flight search tool). The founders are now glad to have been working on Wanderlog for 6 years, and are excited to make travelersâ€™ lives easier!', 'extracted_skills': [{'generated_text': 'hard_skills'}]}\n",
      "{'title': 'Software Engineer I, Fullstack', 'company': 'Pinterest', 'location': 'United States', 'url': 'https://www.linkedin.com/jobs/view/software-engineer-i-fullstack-at-pinterest-4140316003?position=4&pageNum=0&refId=gwJNwjrnv3xMXSUwJOU0kg%3D%3D&trackingId=Q%2F6j1zdpCuHmHNGfUJO2bA%3D%3D', 'description': \"About PinterestMillions of people across the world come to Pinterest to find new ideas every day. Itâ€™s where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, youâ€™ll be challenged to take on work that upholds this mission and pushes Pinterest forward. Youâ€™ll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.Creating a life you love also means finding a career that celebrates the unique perspectives and experiences that you bring. As you read through the expectations of the position, consider how your skills and experiences may complement the responsibilities of the role. We encourage you to think through your relevant and transferable skills from prior experiences.Our new progressive work model is called PinFlex, a term thatâ€™s uniquely Pinterest to describe our flexible approach to living and working. Visit ourPinFlexlanding page to learn more.We are looking for inquisitive, well-rounded Full-stack engineers to join our engineering teams. Working closely with product managers, designers, and backend engineers, youâ€™ll play an important role in enabling the newest technologies and experiences. You will build robust frameworks & features. You will empower both developers and Pinners alike. Youâ€™ll have the opportunity to find creative solutions to thought-provoking problems. Even better, because we covet the kind of courageous thinking thatâ€™s required in order for big bets and smart risks to pay off, youâ€™ll be invited to create and drive new initiatives, seeing them from inception through to technical design, implementation, and release.What Youâ€™ll DoBuild out full-stack Pinner-facing features to power the future of inspiration on PinterestContribute to and lead each step of the product development process, from ideation to implementation to release; from rapidly prototyping, running A/B tests, to architecting and building solutions that can scale to support millions of usersPartner with design, product, and backend teams to build end-to-end functionalityPut on your Pinner hat to suggest new product ideas and featuresEmploy automated testing to build features with a high degree of technical quality, taking responsibility for the components and features you developGrow as an engineer by working with world-class peers on varied and high impact projectsWhat Weâ€™re Looking ForBachelorâ€™s degree in Computer Science, a related field or equivalent experience1+ year of industry full-stack development experience, building consumer or business facing productsProficiency in one or more common backend and frontend tech stacks: e.g. Javascript, React, API, storage, caching and data processingExperience in following best practices in writing reliable and maintainable code that may be used by many other engineersAbility to keep up-to-date with new technologies to understand what should be incorporatedStrong collaboration and communication skillsIn-Office Requirement StatementWe let the type of work you do guide the collaboration style. That means we're not always working in an office, but we continue to gather for key moments of collaboration and connection.This role will need to be in the office for in-person collaboration 1-2 times every 6 months and therefore can be situated anywhere in the country.Relocation Statement:This position is not eligible for relocation assistance. Visit our PinFlex page to learn more about our working model.At Pinterest we believe the workplace should be equitable, inclusive, and inspiring for every employee. In an effort to provide greater transparency, we are sharing the base salary range for this position. The position is also eligible for equity. Final salary is based on a number of factors including location, travel, relevant prior experience, or particular skills and expertise.Information regarding the culture at Pinterest and benefits available for this position can be found here.US based applicants only$98,693â€”$203,191 USDOur Commitment To DiversityPinterest is an equal opportunity employer and makes employment decisions on the basis of merit. We want to have the best qualified people in every job. All qualified applicants will receive consideration for employment without regard to race, color, ancestry, national origin, religion or religious creed, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, age, marital status, status as a protected veteran, physical or mental disability, medical condition, genetic information or characteristics (or those of a family member) or any other consideration made unlawful by applicable federal, state or local laws. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you require a medical or religious accommodation during the job application process, please complete this form for support.\", 'extracted_skills': [{'generated_text': 'hard_skills'}]}\n",
      "{'title': 'Software Engineer (L5), Python Platform', 'company': 'Netflix', 'location': 'United States', 'url': 'https://www.linkedin.com/jobs/view/software-engineer-l5-python-platform-at-netflix-4142024539?position=5&pageNum=0&refId=gwJNwjrnv3xMXSUwJOU0kg%3D%3D&trackingId=gVobwuXtT5RHgmCTASRghQ%3D%3D', 'description': \"Netflix is one of the world's leading entertainment services, with 283 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.Our application development platform teams enable the underlying technology and best practices for engineering at Netflix. We work to provide Netflix developers with the best support, solutions and approaches to leverage common centralized needs. Python is one of the top three languages used at Netflix, critical to our machine learning, data science, and animation pipeline efforts, to name a few. The Python Platform team is relatively new to the application development platform teams and as such, provides an exciting opportunity for you to shape the future of Python at Netflix.Your day-to-dayDesign and promote internal Python libraries that address common challenges faced by Netflix's Python developers. Refine and ensure the foundational Python capabilities operate seamlessly for customers.Understand and improve Python development experience by bringing in best practices and the latest technologies into runtime management, dependency resolution/management, testing, delivery, and operation.Work backward from Python developers to understand their pain, and collaborate with partner teams to provide an opinionated, batteries-included software development lifecycle for Python developers.Safely apply massive code refactoring changes to thousands of git repositories for migration and upgrade needs.Participate in the teamâ€™s support and on-call rotations.What We Need From YouExtensive experience with authoring Python libraries, that will be used across multiple environments, such as batch jobs, data streaming, training, and web services.Deep understanding of common software engineering challenges, such as observability, security, configuration, caching, and IPC.Strong expertise in Python build systems and proficiency in dependency management.Demonstrated ability to collaborate cross-functionally with other Platform teams.Able to comfortably navigate the ambiguity of a wide range of customer and partner needs, working to create the best products for the business priorities.Wearing different hats as needed for the team, including project and product management.Nice to HavesExperience with any of these domains:Machine Learning (e.g., TensorFlow, PyTorch, scikit-learn)Data Engineering (e.g., Jupyter Notebooks, Spark, pandas, numpy)Web Framework (e.g. Flask, FastAPI)Working knowledge of CondaOur culture is unique, and we live by our values, allowing you to do your best work and grow. To learn more about Productivity Engineering, listen to this podcast.At Netflix, we carefully consider a wide range of compensation factors to determine your personal top of the market. We rely on market indicators to determine compensation and consider your specific job family, background, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location.Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $100,000 - $720,000.This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Netflix has a unique culture and environment. Learn more here.Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.Job is open for no less than 7 days and will be removed when the position is filled.\", 'extracted_skills': [{'generated_text': 'hard_skills'}]}\n",
      "{'title': 'Full Stack Software Engineer', 'company': 'Under Armour', 'location': 'United States', 'url': 'https://www.linkedin.com/jobs/view/full-stack-software-engineer-at-under-armour-4133127557?position=6&pageNum=0&refId=gwJNwjrnv3xMXSUwJOU0kg%3D%3D&trackingId=QZnuyYq2ui4OqFYkt%2BXK9Q%3D%3D', 'description': 'Values & InnovationAt Under Armour, we are committed to empowering those who strive for more, and the company\\'s values - Act Sustainably, Celebrate the Wins, Fight on Together, Love Athletes and Stand for Equality - serve as both a roadmap for our teams and the qualities expected of every teammate.Our Values define and unite us, the beliefs that are the red thread that connects everyone at Under Armour. Our values are rallying cries, reminding us why we\\'re here, and fueling everything we do.Our pursuit of better begins with innovation and with our team\\'s mission of being the best. With us, you get the freedom to go further - no matter your role. That means developing, delivering, and selling the state-of-the-art products and digital tools that make top performers even better.If you are a current Under Armour teammate, apply to this position on theInternal Career Site Here.Purpose of RoleUnder Armour is seeking a Full Stack Software Engineer to help build fast, frictionless web experiences across the globe as part of our growing Ecommerce Engineering team. While the role is primarily focused on front-end development, there are opportunities to learn and contribute to back-end systems and other technologies. The ideal candidate has a strong foundation in web development, a passion for learning, and enjoys collaborating with cross-functional partners to deliver exceptional digital experiences.Your ImpactDevelop high-quality software with a focus on front-end development using modern frameworks and tools.Collaborate with team members to design, build, and maintain web applications and components.Participate in the software development lifecycle, including requirements gathering, development, testing, and deployment.Troubleshoot and debug issues to maintain high performance and reliability.Learn and contribute to back-end systems and APIs as needed.Work closely with senior engineers and cross-functional partners to deliver scalable and innovative solutions.QualificationsBachelor\\'s degree with typically 2 years of relevant experience, OR Master\\'s degree without experience, OR Typically 6 years of relevant work experience without degree.Willingness to learn and work with back-end technologies like Node.js and REST/GraphQL APIs.Ability to work in an agile development environment and collaborate effectively with cross-functional teams.Solid Understanding Of Modern Front-end Development TechnologiesReact, TypeScript, JavaScript, CSS/SCSS, and HTML.Experience with Next.js is a plus.Exposure To Or Interest In LearningTagging & Analytics: Adobe Analytics, Tealium, Google Tag Manager.Content Management Systems: CoreMedia, Contentful.E-Commerce Systems: Salesforce Commerce Cloud, Shopify, etc.A/B Testing Tools: Adobe Target, AB Tasty, Evergage.Workplace LocationLocation: Fully RemoteReturn to Work Designation: Fully RemoteTravel: minimalLicenses/Certifications: N/ARelocationNo relocation providedBase Compensation$104,515.00 - $143,708.40 USDMost new hires fall within this range and have the opportunity to earn more over time. Initial placement within the salary range, however, is based on an individual\\'s relevant knowledge, skills and experience for the position. UA is committed to helping our teammates succeed and advance in their careers. Base salary is only one component of our competitive Total Rewards package.Benefits & PerksPaid \"UA Give Back\" Volunteer Days: Work alongside your team to support initiatives in your local communityUnder Armour Merchandise DiscountsCompetitive 401(k) plan matchingMaternity and Parental Leave for eligible and FMLA-eligible teammatesHealth & fitness benefits, discounts and resources- We offer teammates across the country programs to promote physical activity and overall well-beingOur Commitment to DiversityAt Under Armour, we are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and teammates without regard to race, color, religion or belief, sex, pregnancy (including childbirth, lactation and related medical conditions), national origin, age, physical and mental disability, marital status, sexual orientation, gender identity, gender expression, genetic information (including characteristics and testing), military and veteran status, family or paternal status and any other characteristic protected by applicable law. Under Armour believes that diversity and inclusion among our teammates is critical to our success as a global company, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool. Accommodation is available for applicants with disabilities upon request.', 'extracted_skills': [{'generated_text': 'hard_skills'}]}\n",
      "{'title': 'Software Quality Engineer', 'company': 'Microsoft', 'location': 'Bengaluru, Karnataka, India', 'url': 'https://in.linkedin.com/jobs/view/software-quality-engineer-at-microsoft-4131148243?position=7&pageNum=0&refId=gwJNwjrnv3xMXSUwJOU0kg%3D%3D&trackingId=J8NPqkVKx%2FbTJ735N25HjA%3D%3D', 'description': \"Have you ever imagined a world with an infinite amount of storage available and accessible to everyone? A place where everyone in the world can easily access their data from anywhere at any time via any means (e.g., mobile phones, tablets, PCs, smart devices, etc.). Did you ever desire a universally accessible storage system to record all the knowledge known to mankind or to store all the data collected from all the scientists in the world for them to collaborate upon? Do you want to be part of a team that strives to bring these to reality?As a Software Quality Engineer in the Azure Storage team, you will build, improve and support highly scalable, performant services that deliver highly reliable, secure and available access to storage for our customers. You will face challenges of monitoring, analyzing, and designing for ever-growing data needs of our customers and for ensuring data privacy, protection and compliance. This opportunity will allow you to develop your technical skills in cloud services and storage, accelerate career growth, and provide an opportunity to work in a highly dynamic, flexible, and globally distributed team.Microsoftâ€™s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.ResponsibilitiesYou will identify the scope of testing to create a quality plan for multiple features. Youâ€™ll also create commitments for test plans in multiple features to estimate the scope of work and agree on requirements with some guidance from others.You will work with partners across teams by creating test plans for multiple features and contributes effort to get test plans for a feature reviewed by other teams (e.g., requirement writers, design architects) to solidify the test plan.By leveraging available data, youâ€™ll work within multiple features or a broad/complex feature area to identify areas where additional exploration, development, or testing is required. Youâ€™ll also help build complex custom visualizations to ensure product testing coverage.You will be contributing to efforts to apply best practices in automation to create and implement automated testing procedures using scripting languages (e.g., C#, Python). Creates automated regression release testing when possible.Maintaining and applying automation tools and encourages team members to apply automation throughout the testing process (e.g., during development). Writing code or leveraging tools and technology to eliminate repetitive tasks to reduce manual work for multiple features.QualificationsRequired Qualifications:Bachelor's Degree in Engineering, Computer Science, or related field AND 1+ year(s) software industry or internship experience in system testing (involving networking / storage / virutalization product line) with coding in languages including, but not limited to, C, C++, C#, or Python.OR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Engineering, Computer Science,OR related field AND 2+ years software industry experience in system testing (involving networking / storage / virutalization product line) with coding in languages including, but not limited to, C, C++, C#, or Python.OR Master's Degree in Engineering, Computer Science, or related field AND 2+ years technical engineering experience with coding in languages including, but not limited to, C, C++, C#, or Python.OR equivalent experience.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.\", 'extracted_skills': [{'generated_text': \"'hard_skills'\"}]}\n",
      "{'title': 'Software Engineer I', 'company': 'ExtraHop', 'location': 'Seattle, WA', 'url': 'https://www.linkedin.com/jobs/view/software-engineer-i-at-extrahop-4131392213?position=8&pageNum=0&refId=gwJNwjrnv3xMXSUwJOU0kg%3D%3D&trackingId=BWnqT3%2FbzYSG6wTeheq1TQ%3D%3D', 'description': \"At ExtraHop, we're on a mission to help organizations achieve complete visibility, real-time threat detection, and proactive security through cutting-edge network detection and response (NDR) technology. Our NDR product is a market leader, providing our customers with the ability to detect, investigate, and respond to threats faster than ever before.Weâ€™re proud of the work we do and the recognition weâ€™ve received, including our recent Gartner Peer Insights award, which reflects the trust and satisfaction our customers have in our solutions.If you're passionate about innovation, dedicated to protecting digital infrastructures, and ready to make a real impact, we invite you to join our team and help us shape the future of cybersecurity.Position SummaryThe Cloud teamâ€™s mission is to design and deliver a fault-resilient, highly available, and customer-focused platform that sets the standard for innovation and reliability. In this role, you will collaborate with a talented team to develop a large-scale, secure, and scalable platform leveraging cutting-edge technologies.This opportunity is ideal for those who are passionate about cybersecurity, driven by the pursuit of simplification, and eager to explore and implement technology best practices at the forefront of the industry. Joining this team will not only allow you to work on impactful, state-of-the-art solutions but also equip you with expertise that will serve as a strong foundation for an exceptional career trajectory in cloud technology and security.Key ResponsibilitiesAutomate infrastructure and processes using tools like Terraform and Ansible.Participate in continuous integration testing and support multiple releases per week to ensure rapid delivery and high reliability.Develop and maintain cloud services primarily in Go, with a focus on security, scalability and stability.Contribute to the design and implementation of a fault-tolerant architecture for cloud services to ensure platform reliability and automated remediation.Engage with cutting-edge cloud technologies to build and enhance ExtraHop platform.Implement automation and efficient systems to reduce manual interventionsRequired QualificationsBachelorâ€™s degree in Computer Science, Engineering or a related disciplineNew grad to 1+ year of experienceExcellent engineering chopsKnowledge of Go, Python, or an equivalent programming language with strong programming conceptSelf-starter with a strong problem-solving track record and ability to grow and learnGood communicator and collaborator who can iterate quicklyPreferred QualificationsExperience and understanding around containers and related technologies (Kubernetes / Docker / HashiCorp - Packer, Vault, and Terraform).Experience and understanding with building and scaling distributed, highly available systemsExperience with some cloud services on AWS (EKS / RDS / S3 / SQS / EC2 / IAM)About ExtrahopExtraHop is the cybersecurity partner enterprises trust to reveal the unknown and unmask the attack. Weâ€™re on a mission to protect and propagate trust by revealing the cybertruth, and we partner with every customer, every day, to uncover it. Our Reveal(x) 360 platform is the only network detection and response solution delivering the 360-degree visibility needed to see everything on the network. When organizations have full network transparency with ExtraHop, they can see more, know more, and stop more cyberattacks.ExtraHopis recognized by leading organizations for both itsinnovation in the marketand itscommitment to building a world-class team. Weâ€™ve been recognized as a â€œCustomerâ€™s Choiceâ€ by Gartner Peer Insightsâ„¢ Voice of the Customer, and as a Leader in the Forrester WaveÂ®: Network Analysis and Visibility, Q2 2023. ExtraHop has won AI Breakthrough Awards four times (2018-2020, 2023) and our Channel Partner program has received a 5-star rating from CRN for our 2023 Partner Program Guide. Our flagship product, Reveal(x), has received numerous accolades, including a 2022 Edison Award for Cybersecurity.BenefitsEmployees' wellbeing is top of mind for the ExtraHop team. Employees and their families will have the option to participate in the following benefits:Health, Dental, and Vision BenefitsFlexible PTO, Sick Time Prorated Based on Date of Hire, and All Federal Holidays (US Only) + 3 Days of Paid Volunteer TimeNon-Commissioned Positions may be eligible to participate in the Annual Discretionary Bonus PlanFSA and Dependent Care Accounts + EAP, where applicableEducational Reimbursement401k with Employer Match or Pension where applicablePet Insurance (US Only)Parental Leave (US Only)Hybrid and Remote Work ModelCandidates should note that the Company may modify reporting relationships, job titles and compensation, including commissions and benefits, from time to time at its sole discretion, as it deems necessary, with or without prior notice.We are intentional about our culture, diversity, and inclusion, and we welcome everyone to come ready to participate in contributing to this truly unique environment. At ExtraHop, we believe that the best products, services, and companies are built by strong teams that include a diversity of backgrounds, perspectives, ideas, and experiences. We are committed to supporting and enabling growth and opportunity for every employee at every level. This is the foundation of our success.We are equally committed to equal employment opportunity, and it is foundational to how we recruit and hire our talented team. Employment is determined based upon capabilities and qualifications without discrimination on the basis of race, color, religion, sex, gender identification and expression, marital status, military status, pregnancy (including but not limited to potential pregnancy and pregnancy-related conditions), sexual orientation, age , national origin, ancestry, citizenship or immigration status, disability ,, genetic information, or any other protected class as established by law.Our people are our most important competitive advantage, leading the charge cyber criminals and insider threats.Ready to join us? #Extrahop #Security #NDR #informationsecurity #cybersecurity #cloudsecurity #infosec\", 'extracted_skills': [{'generated_text': 'hard_skills'}]}\n",
      "{'title': 'Full Stack Software Engineer', 'company': 'Resonate', 'location': 'Washington, DC', 'url': 'https://www.linkedin.com/jobs/view/full-stack-software-engineer-at-resonate-4128463915?position=9&pageNum=0&refId=gwJNwjrnv3xMXSUwJOU0kg%3D%3D&trackingId=W1WP%2F%2BAmUPNkj2NIEz9Jxw%3D%3D', 'description': 'Resonate is revolutionizing the marketing and advertising landscape with cutting-edge technology that seamlessly combines real-time survey data, insights on U.S. consumers, and online behavioral data into a single, powerful platform. By pioneering a groundbreaking approach, Resonate enables brands to identify, understand, and engage highly targeted audiences on a deeper level. Our platform uncovers thousands of individual attributes that reveal the core values, beliefs, and motivations driving consumer behavior. We go beyond surface-level data to understand the \"why\" behind consumers\\' actions, empowering businesses to connect with the products, companies, and causes that matter most to their audiences.Join Resonate as aFull Stack Software Engineerand play a pivotal role in shaping our Application Engineering team. You\\'ll leverage cutting-edge technologies like Spring Boot and modern JavaScript frameworks to build scalable, high-performance applications that redefine consumer data and intelligence. This role is ideal for engineers with a passion for full-stack development, cloud technologies, and AI integration. Thriving in a collaborative, fast-paced environment, valuing ownership of work, and tackling complex challenges are key traits we seek in our team members.Key ResponsibilitiesDesign, develop, and maintain full-stack features, from database architecture to front-end UI, using Spring Boot and modern JavaScript frameworks.Build responsive, user-friendly UI components for single-page applications (SPAs).Develop and maintain Spring Boot microservices supporting business-critical features in an agile environment.Leverage AWS cloud technologies for deployment, scaling, and maintenance.Integrate AI-driven solutions to enhance product workflows and user experiences.Optimize and maintain relational databases, ensuring performance and scalability.Develop and document RESTful APIs for seamless system integration.Write robust unit, integration, and end-to-end tests for new features.Collaborate with cross-functional teams, including product managers and designers, to meet evolving requirements.Participate in CI/CD pipelines for efficient and reliable deployments.Troubleshoot, debug, and resolve issues across the stack.Required QualificationsStrong fundamentals in computer science and software engineering principles.2-3 years of full-stack development experience, including:Proficiency in Spring Boot for backend development.Expertise in JavaScript frameworks like React, Angular, or Ember.js.Relational database design, SQL optimization, and integration experience (e.g., Hibernate, JPA).Hands-on experience with AWS services (e.g., EC2, S3, RDS, Lambda).Familiarity with AI concepts and integrating them into software systems.Knowledge of distributed system design and scalable architecture.Experience with CI/CD pipelines and testing frameworks.Strong communication skills and a problem-solving mindset.Desired QualificationsAdvanced proficiency in HTML, CSS, and JavaScript for SPAs.Experience developing SaaS products in a commercial setting.Background in digital media, online advertising, or analytical applications.Experience managing large-scale SQL databases.Understanding of AI technologies like machine learning models and natural language processing (NLP).BenefitsBesides the opportunity to work with smart, fun, hard-working Resonate employees, you will have uncapped growth potential, a work/life balance, and a competitive suite of benefits.LocationAt Resonate, we take a remote-first approach to work, offering a flexible environment that empowers our team to collaborate seamlessly across different locations. While we embrace remote work, we also encourage thoughtful and intentional in-person collaboration to foster connection and teamwork when needed. Whether you\\'re working from home or joining us in one of our state-of-the-art offices, you\\'ll have the tools and resources you need to succeed.Resonate is headquartered in Reston, VA, with offices in New York City and Washington, D.C. Join us and be part of a team that\\'s changing the industry!Our EEO Statement:Resonate is an equal opportunity employer that is committed to diversity and inclusion in the workplace. We prohibit discrimination and harassment of any kind based on race, color, sex, religion, sexual orientation, national origin, disability, genetic information, pregnancy, or any other protected characteristic as outline by federal, state, or local laws.Find out more about our story atwww.resonate.com.', 'extracted_skills': [{'generated_text': 'hard_skills'}]}\n",
      "{'title': 'Software Engineer - Intern', 'company': 'ZipRecruiter', 'location': 'Santa Monica, CA', 'url': 'https://www.linkedin.com/jobs/view/software-engineer-intern-at-ziprecruiter-4134409289?position=10&pageNum=0&refId=gwJNwjrnv3xMXSUwJOU0kg%3D%3D&trackingId=T5V87LqrQWQmCfkPM84j4A%3D%3D', 'description': \"We offer a hybrid work environment. Most US-based positions can also be performed remotely (any exceptions will be noted in the Minimum Qualifications below.)Our Mission:To actively connect people to their next great opportunity.Who We Are:ZipRecruiter is the fastest-growing online employment marketplace for both desktop and mobile traffic. Powered by AI-driven smart matching technology, weâ€™re building connections for millions of job seekers and businesses of all sizes through innovative mobile, web, and email services, as well as through partnerships with the best job boards on the web. As the #1 rated job search app on iOS & Android for the past 6 years, our customers are our priority.About the Team:Weâ€™re looking for software engineering interns who are passionate about building an intuitive experience for our marketplace serving millions of jobseekers and tens of thousands of customers. Our teams have a unique opportunity to work at scale, building fast, scalable, and effective applications that help connect people to their next job.As a summer intern, youâ€™ll join our12 week programin ourSanta Monica officeand work on a combination of sprint work with your team and a project designed to provide you with the ability to develop high quality, high-performance code, consider trade-offs, iterate on solutions and expand on scope and scalability. You'll get the opportunity to become more deeply specialized in one of the following disciplines:Big Data, Full Stack, Machine Learning, Mobile - iOS, Mobile - Androidto better prepare you for a full-time career. Whether itâ€™s supporting our job seekers, employers, or internal developers, you will have a real impact on and be able to shape the ZipRecruiter product.About the Job:Take part in the full life cycle of user-facing applications at scale, from design to implementation and testing to productionDevelop a strong understanding of the business, industry, codebase, and/or systemsWrite, test, instrument, and deploy high quality code with good test coverage, using modern abstractions and frameworks to our Kubernetes environmentHelp drive the innovation and evolution of ZipRecruiterMinimum Qualifications:Currently enrolled in a full-time, Computer Science degree-seeking program or related technical field with an expected graduation date between December 2025 and November 2026.Demonstrated foundation in software engineering through previous internship experience or equivalent practical experienceFluency with at least 1 general purpose programming language (e.g., Python, Java)Ability to work in-person in our Santa Monica office for the summerAn interest in becoming more specialized in at least one of the following disciplines: Big Data, Full Stack, Machine Learning, Mobile - iOS, Mobile - AndroidPreferred Qualifications:Fluency in multiple programming languages or ability to pick up new languages quicklyExperience working with both non-relational and relational database systemsExposure to developing client side interactions using frameworks like React along with plain Javascript, CSS and HTMLAnalytical and problem-solving skills along with a self-starter mentalityPassion for and experience with creating an intuitive, user-friendly experienceAs part of our team you'll enjoy:Competitive salaryExceptional benefits and perksThe US base pay range for this full-time position is$45.00/hr - $50.00/hr. Our pay ranges are determined by role, level, and location, and the range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location, role-related knowledge and skills, depth of experience, relevant education or training, and additional role-related considerations.Depending on the position offered, equity, bonuses, commission, or other forms of compensation may also be provided as part of a total compensation package, in addition to a full range of medical, financial, and other benefits.ZipRecruiter is proud to be an equal opportunity employer and provides equal employment opportunities (EEO) to all employees and applicants without regard to race, color, religion, sex, national origin, age, disability, veteran status, sexual orientation, gender identity or genetics.Privacy Notice:For information about ZipRecruiter's collection and processing of job applicant personal data for this job, please see our Privacy Notice at: https://www.ziprecruiter.com/careers/job-applicant-privacy-notice\", 'extracted_skills': [{'generated_text': 'hard_skills'}]}\n"
     ]
    }
   ],
   "source": [
    "# Trying the API!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "from huggingface_hub.inference_api import InferenceApi\n",
    "\n",
    "# Set your Hugging Face API token and choose a model repository\n",
    "MODEL_REPO_ID = 'google/flan-t5-base'\n",
    "\n",
    "# Initialize the Inference API client\n",
    "inference = InferenceApi(repo_id=MODEL_REPO_ID, token=HF_API_TOKEN)\n",
    "\n",
    "# Function to scrape job postings with descriptions\n",
    "def scrape_jobs_with_descriptions(keywords, location, f_WT, pages_to_scrape, headers):\n",
    "    keywords_encoded = quote(keywords)\n",
    "    location_encoded = quote(location)\n",
    "    jobs = []\n",
    "\n",
    "    for page in range(pages_to_scrape):\n",
    "        url = (\n",
    "            f\"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/\"\n",
    "            f\"search?keywords={keywords_encoded}&location={location_encoded}&f_WT={f_WT}&start={25 * page}\"\n",
    "        )\n",
    "        print(f\"Scraping job list page: {url}\")\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch page {page + 1}: {response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        divs = soup.find_all(\"div\", class_=\"base-card\")\n",
    "\n",
    "        for div in divs:\n",
    "            try:\n",
    "                title = div.find(\"h3\", class_=\"base-search-card__title\").text.strip()\n",
    "                company = div.find(\"h4\", class_=\"base-search-card__subtitle\").text.strip()\n",
    "                location = div.find(\"span\", class_=\"job-search-card__location\").text.strip()\n",
    "                job_link_tag = div.find(\"a\", class_=\"base-card__full-link\")\n",
    "                job_url = job_link_tag[\"href\"] if job_link_tag else \"No URL found\"\n",
    "                job_description = (\n",
    "                    fetch_job_description(job_url, headers)\n",
    "                    if job_url != \"No URL found\"\n",
    "                    else \"No description available\"\n",
    "                )\n",
    "                jobs.append({\n",
    "                    \"title\": title,\n",
    "                    \"company\": company,\n",
    "                    \"location\": location,\n",
    "                    \"url\": job_url,\n",
    "                    \"description\": job_description\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing job: {e}\")\n",
    "    return jobs\n",
    "\n",
    "# Function to fetch the job description from the individual job posting\n",
    "def fetch_job_description(job_url, headers):\n",
    "    try:\n",
    "        response = requests.get(job_url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch job page: {job_url}\")\n",
    "            return \"Failed to fetch job description\"\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        description_div = soup.find(\"div\", class_=\"show-more-less-html__markup\")\n",
    "        if description_div:\n",
    "            return description_div.get_text(strip=True).replace(\"\\n\", \" \")\n",
    "        return \"No description available\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching job description: {e}\")\n",
    "        return \"Error fetching job description\"\n",
    "\n",
    "# Function to extract skills using the Hugging Face Inference API client wrapper\n",
    "def extract_skills(job_description):\n",
    "    prompt = (\n",
    "        \"Extract all relevant hard and soft skills from the following job description. \"\n",
    "        \"Return the results as JSON with keys 'hard_skills' and 'soft_skills'.\\n\\n\"\n",
    "        f\"Job Description: {job_description}\"\n",
    "    )\n",
    "    response = inference(prompt)\n",
    "    return response\n",
    "\n",
    "# Configuration for scraping\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "keywords = \"software engineer\"\n",
    "location = \"Remote\"\n",
    "f_WT = \"2\"  # Remote jobs\n",
    "pages_to_scrape = 1  # Adjust as needed\n",
    "\n",
    "# Scrape job postings\n",
    "jobs_with_descriptions = scrape_jobs_with_descriptions(keywords, location, f_WT, pages_to_scrape, headers)\n",
    "\n",
    "# Extract skills for each job description using the client wrapper\n",
    "for job in jobs_with_descriptions:\n",
    "    skills = extract_skills(job[\"description\"])\n",
    "    job[\"extracted_skills\"] = skills\n",
    "\n",
    "# Print job details with the extracted skills\n",
    "for job in jobs_with_descriptions:\n",
    "    print(job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkedin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
